#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# File: src/vocal_smart_splitter/core/dual_path_detector.py
# AI-SUMMARY: åŒè·¯äººå£°åœé¡¿æ£€æµ‹å™¨ï¼Œç»“åˆæ··éŸ³è·¯å¾„å’Œåˆ†ç¦»è·¯å¾„è¿›è¡Œäº¤å‰éªŒè¯ï¼Œæ˜¾è‘—æå‡æ£€æµ‹ç²¾åº¦

import numpy as np
import logging
import time
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass

from ..utils.config_manager import get_config
from .vocal_pause_detector import VocalPauseDetectorV2, VocalPause
from .enhanced_vocal_separator import EnhancedVocalSeparator, SeparationResult

logger = logging.getLogger(__name__)

@dataclass
class ValidatedPause:
    """ç»è¿‡äº¤å‰éªŒè¯çš„åœé¡¿ç»“æ„"""
    start_time: float                    # åœé¡¿å¼€å§‹æ—¶é—´
    end_time: float                      # åœé¡¿ç»“æŸæ—¶é—´
    duration: float                      # åœé¡¿æ—¶é•¿
    position_type: str                   # ä½ç½®ç±»å‹ï¼š'head', 'middle', 'tail'
    confidence: float                    # æœ€ç»ˆç½®ä¿¡åº¦ (0-1)
    cut_point: float                     # ä¼˜åŒ–åçš„åˆ‡å‰²ç‚¹æ—¶é—´
    
    # éªŒè¯ä¿¡æ¯
    mixed_detection: bool = False        # æ··éŸ³è·¯å¾„æ˜¯å¦æ£€æµ‹åˆ°
    separated_detection: bool = False    # åˆ†ç¦»è·¯å¾„æ˜¯å¦æ£€æµ‹åˆ°
    separation_confidence: float = 0.0   # åˆ†ç¦»è´¨é‡ç½®ä¿¡åº¦
    validation_method: str = "unknown"   # éªŒè¯æ–¹æ³•
    
    # åŸå§‹åœé¡¿å¼•ç”¨
    mixed_pause: Optional[VocalPause] = None
    separated_pause: Optional[VocalPause] = None

@dataclass  
class DualDetectionResult:
    """åŒè·¯æ£€æµ‹æ€»ç»“æœ"""
    validated_pauses: List[ValidatedPause]
    processing_stats: Dict
    quality_report: Dict

class DualPathVocalDetector:
    """åŒè·¯äººå£°åœé¡¿æ£€æµ‹å™¨
    
    æ ¸å¿ƒç†å¿µï¼š
    1. åŒè·¯å¹¶è¡Œï¼šåŒæ—¶åœ¨æ··éŸ³å’Œåˆ†ç¦»äººå£°ä¸Šæ£€æµ‹åœé¡¿
    2. äº¤å‰éªŒè¯ï¼šé€šè¿‡ä¸¤ä¸ªç»“æœçš„å¯¹æ¯”å’Œèåˆæå‡ç²¾åº¦
    3. æ™ºèƒ½é™çº§ï¼šåˆ†ç¦»å¤±è´¥æ—¶è‡ªåŠ¨é€€å›å•è·¯æ£€æµ‹
    4. è´¨é‡è¯„ä¼°ï¼šæŒç»­ç›‘æ§å„è·¯å¾„çš„æ£€æµ‹è´¨é‡
    """
    
    def __init__(self, sample_rate: int = 44100):
        """åˆå§‹åŒ–åŒè·¯æ£€æµ‹å™¨
        
        Args:
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
        """
        self.sample_rate = sample_rate
        
        # ä»é…ç½®åŠ è½½å‚æ•°
        self.enable_dual_detection = get_config('enhanced_separation.dual_detection.enable_cross_validation', True)
        self.pause_matching_tolerance = get_config('enhanced_separation.dual_detection.pause_matching_tolerance', 0.2)
        self.confidence_boost = get_config('enhanced_separation.dual_detection.confidence_boost_factor', 1.2)
        self.mixed_weight = get_config('enhanced_separation.dual_detection.mixed_audio_weight', 0.4)
        self.separated_weight = get_config('enhanced_separation.dual_detection.separated_audio_weight', 0.6)
        self.min_separation_quality = get_config('enhanced_separation.min_separation_confidence', 0.7)
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.mixed_detector = VocalPauseDetectorV2(sample_rate)  # æ··éŸ³æ£€æµ‹å™¨
        self.separator = EnhancedVocalSeparator(sample_rate)     # å¢å¼ºåˆ†ç¦»å™¨
        self.separated_detector = VocalPauseDetectorV2(sample_rate)  # åˆ†ç¦»åæ£€æµ‹å™¨
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_detections': 0,
            'dual_path_used': 0,
            'single_path_fallback': 0,
            'high_quality_separations': 0,
            'processing_times': []
        }
        
        logger.info(f"åŒè·¯æ£€æµ‹å™¨åˆå§‹åŒ– - å¯ç”¨åŒè·¯: {self.enable_dual_detection}")
        
    def detect_with_dual_validation(self, audio: np.ndarray) -> DualDetectionResult:
        """æ‰§è¡ŒåŒè·¯æ£€æµ‹å’Œäº¤å‰éªŒè¯
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘æ•°æ®
            
        Returns:
            DualDetectionResult: åŒ…å«éªŒè¯ååœé¡¿å’Œç»Ÿè®¡ä¿¡æ¯
        """
        start_time = time.time()
        self.stats['total_detections'] += 1
        
        logger.info("å¼€å§‹åŒè·¯äººå£°åœé¡¿æ£€æµ‹...")
        
        # è·¯å¾„Aï¼šæ··éŸ³æ£€æµ‹ï¼ˆæ€»æ˜¯æ‰§è¡Œï¼‰
        mixed_pauses = self._detect_on_mixed_audio(audio)
        logger.debug(f"æ··éŸ³è·¯å¾„æ£€æµ‹åˆ° {len(mixed_pauses)} ä¸ªåœé¡¿")
        
        # è·¯å¾„Bï¼šåˆ†ç¦»æ£€æµ‹ï¼ˆæ ¹æ®é…ç½®å’Œåˆ†ç¦»è´¨é‡å†³å®šï¼‰
        separated_pauses = []
        separation_result = None
        use_dual_path = False
        
        # æ£€æŸ¥åç«¯çŠ¶æ€
        backend_available = self.separator.is_high_quality_backend_available()
        backend_status = self.separator.backend_status
        
        logger.info(f"åŒè·¯æ£€æµ‹çŠ¶æ€æ£€æŸ¥:")
        logger.info(f"  é…ç½®å¯ç”¨: {self.enable_dual_detection}")
        logger.info(f"  é«˜è´¨é‡åç«¯å¯ç”¨: {backend_available}")
        logger.info(f"  MDX23çŠ¶æ€: {'å¯ç”¨' if backend_status['mdx23']['available'] else 'ä¸å¯ç”¨'}")
        if not backend_status['mdx23']['available'] and 'error' in backend_status['mdx23']:
            logger.info(f"    MDX23é”™è¯¯: {backend_status['mdx23']['error']}")
        logger.info(f"  DemucsçŠ¶æ€: {'å¯ç”¨' if backend_status['demucs_v4']['available'] else 'ä¸å¯ç”¨'}")
        
        # å¼ºåˆ¶å¯ç”¨åŒè·¯æ£€æµ‹ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰ - åªè¦æœ‰åç«¯å°±å°è¯•
        if backend_available:
            logger.info("å¼€å§‹æ‰§è¡Œäººå£°åˆ†ç¦»æ£€æµ‹...")
            try:
                separation_result = self.separator.separate_for_detection(audio)
                logger.info(f"åˆ†ç¦»å®Œæˆ - åç«¯: {separation_result.backend_used}, è´¨é‡: {separation_result.separation_confidence:.3f}")
                
                # å¼ºåˆ¶ä½¿ç”¨åˆ†ç¦»æ£€æµ‹ï¼ˆå¿½ç•¥è´¨é‡é˜ˆå€¼ä»¥æµ‹è¯•åˆ†å‰²æ•ˆæœï¼‰
                logger.info("âœ“ å¼ºåˆ¶å¯ç”¨åˆ†ç¦»æ£€æµ‹ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
                separated_pauses = self._detect_on_separated_audio(separation_result.vocal_track)
                use_dual_path = True  # å¼ºåˆ¶å¯ç”¨åŒè·¯
                self.stats['dual_path_used'] += 1
                
                if separation_result.backend_used in ['mdx23', 'demucs_v4']:
                    self.stats['high_quality_separations'] += 1
                    logger.info(f"âœ“ é«˜è´¨é‡åˆ†ç¦» ({separation_result.backend_used}) æ£€æµ‹åˆ° {len(separated_pauses)} ä¸ªåœé¡¿")
                else:
                    logger.info(f"âœ“ HPSSåå¤‡åˆ†ç¦»æ£€æµ‹åˆ° {len(separated_pauses)} ä¸ªåœé¡¿")
                
                if separation_result.separation_confidence < self.min_separation_quality:
                    logger.warning(f"  è­¦å‘Š: åˆ†ç¦»è´¨é‡è¾ƒä½ ({separation_result.separation_confidence:.3f} < {self.min_separation_quality})")
                    
            except Exception as e:
                logger.error(f"âœ— åˆ†ç¦»æ£€æµ‹å¤±è´¥: {e}")
                logger.info("é€€å›å•è·¯æ£€æµ‹æ¨¡å¼")
                use_dual_path = False
        else:
            logger.warning("âœ— é«˜è´¨é‡åç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨å•è·¯æ£€æµ‹")
            use_dual_path = False
        
        if not use_dual_path:
            self.stats['single_path_fallback'] += 1
            logger.info("ä½¿ç”¨å•è·¯æ£€æµ‹æ¨¡å¼")
            
        # ğŸ¯ æ ¸å¿ƒé€»è¾‘ä¿®å¤ï¼šä¸¥æ ¼æŒ‰ç…§äººå£°åˆ†ç¦»åˆ†å‰²æµç¨‹
        if use_dual_path and separation_result:
            logger.info(f"\n[äººå£°åˆ†ç¦»åˆ†å‰²æ¨¡å¼]")
            logger.info(f"  åˆ†ç¦»åç«¯: {separation_result.backend_used}")
            logger.info(f"  åˆ†ç¦»ç½®ä¿¡åº¦: {separation_result.separation_confidence:.3f}")
            logger.info(f"  æ··éŸ³æ£€æµ‹: {len(mixed_pauses)}ä¸ªåœé¡¿")
            logger.info(f"  åˆ†ç¦»æ£€æµ‹: {len(separated_pauses)}ä¸ªåœé¡¿")
            
            # ğŸ¯ æŒ‰ç…§ç”¨æˆ·è¦æ±‚ï¼šä¸¥æ ¼åŸºäºäººå£°åˆ†ç¦»ç»“æœè¿›è¡Œåˆ†å‰²
            # ç¬¬1æ­¥ï¼šå·²å®Œæˆäººå£°åˆ†ç¦»
            # ç¬¬2æ­¥ï¼šéªŒè¯äººå£°ä¸åŸéŸ³é¢‘æ—¶é•¿ä¸€è‡´æ€§ 
            vocal_duration = len(separation_result.vocal_track) / self.sample_rate
            original_duration = len(audio) / self.sample_rate
            duration_diff = abs(vocal_duration - original_duration)
            
            logger.info(f"  [æ—¶é•¿éªŒè¯] åŸéŸ³é¢‘: {original_duration:.3f}s, äººå£°: {vocal_duration:.3f}s, å·®å¼‚: {duration_diff:.3f}s")
            
            if duration_diff < 0.1:  # æ—¶é•¿å·®å¼‚å°äº0.1ç§’è®¤ä¸ºä¸€è‡´
                logger.info(f"  âœ“ æ—¶é•¿éªŒè¯é€šè¿‡ï¼Œä½¿ç”¨äººå£°åˆ†ç¦»æ£€æµ‹ç»“æœ")
                # ç¬¬3æ­¥ï¼šåŸºäºäººå£°éŸ³é¢‘ç¡®å®šåœé¡¿åˆ†å‰²ç‚¹
                # ç¬¬4æ­¥ï¼šåˆ†å‰²ç‚¹ä»äººå£°æ˜ å°„åˆ°åŸéŸ³é¢‘ï¼ˆæ ·æœ¬ä½ç½®å®Œå…¨å¯¹åº”ï¼‰
                validated_pauses = self._convert_to_validated_pauses(separated_pauses, single_path=False, source="separated")
                logger.info(f"  ğŸ¯ æœ€ç»ˆå†³ç­–: äººå£°åˆ†ç¦»æ£€æµ‹ {len(separated_pauses)}ä¸ªåœé¡¿")
            else:
                logger.warning(f"  âš ï¸ æ—¶é•¿éªŒè¯å¤±è´¥ï¼Œæ—¶é•¿å·®å¼‚è¿‡å¤§: {duration_diff:.3f}s")
                logger.info(f"  é™çº§ä½¿ç”¨æ··éŸ³æ£€æµ‹é¿å…æ—¶é—´è½´é”™è¯¯")
                validated_pauses = self._convert_to_validated_pauses(mixed_pauses, single_path=False, source="mixed")
                logger.info(f"  ğŸ”„ é™çº§å†³ç­–: æ··éŸ³æ£€æµ‹ {len(mixed_pauses)}ä¸ªåœé¡¿")
        else:
            # å•è·¯æ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨æ··éŸ³æ£€æµ‹ç»“æœ
            if mixed_pauses:
                logger.info(f"ä½¿ç”¨æ··éŸ³æ£€æµ‹ç»“æœï¼ˆ{len(mixed_pauses)}ä¸ªåœé¡¿ï¼‰")
                validated_pauses = self._convert_to_validated_pauses(mixed_pauses, single_path=True, source="mixed")
            elif separated_pauses and separation_result and separation_result.separation_confidence > 0.1:
                logger.info(f"é™çº§ä½¿ç”¨åˆ†ç¦»æ£€æµ‹ç»“æœï¼ˆ{len(separated_pauses)}ä¸ªåœé¡¿ï¼Œè´¨é‡: {separation_result.separation_confidence:.3f}ï¼‰")
                validated_pauses = self._convert_to_validated_pauses(separated_pauses, single_path=True, source="separated")
            else:
                logger.warning("æ— æœ‰æ•ˆæ£€æµ‹ç»“æœ")
                validated_pauses = []
        
        # ç»Ÿè®¡å’ŒæŠ¥å‘Š
        processing_time = time.time() - start_time
        self.stats['processing_times'].append(processing_time)
        
        processing_stats = {
            'processing_time': processing_time,
            'backend_used': separation_result.backend_used if separation_result else 'mixed_only',
            'dual_path_used': use_dual_path,
            'mixed_pauses_count': len(mixed_pauses),
            'separated_pauses_count': len(separated_pauses),
            'final_pauses_count': len(validated_pauses),
            'separation_confidence': separation_result.separation_confidence if separation_result else 0.0
        }
        
        quality_report = self._generate_quality_report(validated_pauses, processing_stats)
        
        logger.info(f"åŒè·¯æ£€æµ‹å®Œæˆ - æœ€ç»ˆåœé¡¿æ•°: {len(validated_pauses)}, ç”¨æ—¶: {processing_time:.2f}ç§’")
        
        return DualDetectionResult(
            validated_pauses=validated_pauses,
            processing_stats=processing_stats,
            quality_report=quality_report
        )
    
    def _detect_on_mixed_audio(self, audio: np.ndarray) -> List[VocalPause]:
        """åœ¨æ··éŸ³ä¸Šæ£€æµ‹åœé¡¿ï¼ˆè·¯å¾„Aï¼‰"""
        try:
            # ä½¿ç”¨ç°æœ‰çš„æ··éŸ³æ£€æµ‹å™¨
            return self.mixed_detector.detect_vocal_pauses(audio)
        except Exception as e:
            logger.error(f"æ··éŸ³æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _detect_on_separated_audio(self, vocal_track: np.ndarray) -> List[VocalPause]:
        """åœ¨åˆ†ç¦»äººå£°ä¸Šæ£€æµ‹åœé¡¿ï¼ˆè·¯å¾„Bï¼‰"""
        try:
            # åœ¨çº¯äººå£°è½¨é“ä¸Šæ£€æµ‹ï¼Œç†è®ºä¸Šç²¾åº¦æ›´é«˜
            return self.separated_detector.detect_vocal_pauses(vocal_track)
        except Exception as e:
            logger.error(f"åˆ†ç¦»éŸ³é¢‘æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def _cross_validate_pauses(self, mixed_pauses: List[VocalPause], 
                             separated_pauses: List[VocalPause], 
                             separation_result: SeparationResult) -> List[ValidatedPause]:
        """äº¤å‰éªŒè¯åœé¡¿ï¼ˆæ ¸å¿ƒç®—æ³•ï¼‰"""
        validated = []
        matched_separated_indices = set()  # å·²åŒ¹é…çš„åˆ†ç¦»åœé¡¿ç´¢å¼•
        
        logger.debug("å¼€å§‹åœé¡¿äº¤å‰éªŒè¯...")
        
        # æ­¥éª¤1ï¼šä¸ºæ¯ä¸ªæ··éŸ³åœé¡¿å¯»æ‰¾åˆ†ç¦»åœé¡¿ä¸­çš„åŒ¹é…
        for mixed_pause in mixed_pauses:
            best_match, match_score = self._find_best_matching_pause(mixed_pause, separated_pauses)
            
            if best_match and match_score > 0.5:  # æ‰¾åˆ°å¯ä¿¡åŒ¹é…
                matched_separated_indices.add(separated_pauses.index(best_match))
                validated_pause = self._create_dual_validated_pause(mixed_pause, best_match, separation_result, match_score)
                validated.append(validated_pause)
                logger.debug(f"åŒè·¯éªŒè¯: {mixed_pause.start_time:.2f}s-{mixed_pause.end_time:.2f}s (åŒ¹é…åº¦: {match_score:.3f})")
                
            elif separation_result.separation_confidence > 0.8:
                # åˆ†ç¦»è´¨é‡å¾ˆé«˜ä½†åªæœ‰æ··éŸ³æ£€æµ‹åˆ°ï¼šä¿ç•™ä½†é™ä½ç½®ä¿¡åº¦
                validated_pause = self._create_mixed_only_validated_pause(mixed_pause, separation_result)
                validated.append(validated_pause)
                logger.debug(f"æ··éŸ³ç‹¬æœ‰: {mixed_pause.start_time:.2f}s-{mixed_pause.end_time:.2f}s (è´¨é‡é«˜ï¼Œä¿ç•™)")
            else:
                # åˆ†ç¦»è´¨é‡ä¸€èˆ¬ï¼Œæ··éŸ³æ£€æµ‹çš„åœé¡¿ï¼šè°¨æ…ä¿ç•™
                validated_pause = self._create_mixed_only_validated_pause(mixed_pause, separation_result, penalty=True)
                validated.append(validated_pause)
                logger.debug(f"æ··éŸ³ç‹¬æœ‰: {mixed_pause.start_time:.2f}s-{mixed_pause.end_time:.2f}s (è´¨é‡ä¸­ç­‰ï¼Œé™çº§)")
        
        # æ­¥éª¤2ï¼šå¤„ç†åˆ†ç¦»æ£€æµ‹ç‹¬æœ‰çš„åœé¡¿
        for i, separated_pause in enumerate(separated_pauses):
            if i not in matched_separated_indices:
                # è¿™æ˜¯åˆ†ç¦»æ£€æµ‹ç‹¬æœ‰çš„åœé¡¿ï¼Œè¯„ä¼°å…¶ä»·å€¼
                if separation_result.separation_confidence > 0.85:  # é«˜è´¨é‡åˆ†ç¦»æ‰è€ƒè™‘é‡‡çº³
                    validated_pause = self._create_separated_only_validated_pause(separated_pause, separation_result)
                    validated.append(validated_pause)
                    logger.debug(f"åˆ†ç¦»ç‹¬æœ‰: {separated_pause.start_time:.2f}s-{separated_pause.end_time:.2f}s (é«˜è´¨é‡ï¼Œé‡‡çº³)")
                else:
                    logger.debug(f"åˆ†ç¦»ç‹¬æœ‰: {separated_pause.start_time:.2f}s-{separated_pause.end_time:.2f}s (è´¨é‡ä¸è¶³ï¼Œå¿½ç•¥)")
        
        # æ­¥éª¤3ï¼šæŒ‰æ—¶é—´æ’åº
        validated.sort(key=lambda p: p.start_time)
        
        logger.info(f"äº¤å‰éªŒè¯å®Œæˆ: {len(mixed_pauses)}+{len(separated_pauses)} â†’ {len(validated)} ä¸ªéªŒè¯åœé¡¿")
        return validated
    
    def _find_best_matching_pause(self, target_pause: VocalPause, 
                                candidate_pauses: List[VocalPause]) -> Tuple[Optional[VocalPause], float]:
        """ä¸ºç›®æ ‡åœé¡¿åœ¨å€™é€‰åˆ—è¡¨ä¸­æ‰¾æœ€ä½³åŒ¹é…"""
        best_match = None
        best_score = 0.0
        
        for candidate in candidate_pauses:
            score = self._calculate_pause_similarity(target_pause, candidate)
            if score > best_score:
                best_score = score
                best_match = candidate
        
        return best_match, best_score
    
    def _calculate_pause_similarity(self, pause1: VocalPause, pause2: VocalPause) -> float:
        """è®¡ç®—ä¸¤ä¸ªåœé¡¿çš„ç›¸ä¼¼åº¦åˆ†æ•° (0-1)"""
        # æ—¶é—´é‡å åº¦
        overlap_start = max(pause1.start_time, pause2.start_time)
        overlap_end = min(pause1.end_time, pause2.end_time)
        overlap_duration = max(0, overlap_end - overlap_start)
        
        union_start = min(pause1.start_time, pause2.start_time)
        union_end = max(pause1.end_time, pause2.end_time)
        union_duration = union_end - union_start
        
        # é‡å æ¯”ä¾‹ï¼ˆç±»ä¼¼IoUï¼‰
        overlap_ratio = overlap_duration / union_duration if union_duration > 0 else 0
        
        # æ—¶é—´ä¸­å¿ƒçš„è·ç¦»
        center1 = (pause1.start_time + pause1.end_time) / 2
        center2 = (pause2.start_time + pause2.end_time) / 2
        center_distance = abs(center1 - center2)
        
        # è·ç¦»è¯„åˆ†ï¼ˆè·ç¦»è¶Šè¿‘è¶Šå¥½ï¼‰
        max_distance = self.pause_matching_tolerance * 2
        distance_score = max(0, 1 - (center_distance / max_distance))
        
        # æ—¶é•¿ç›¸ä¼¼æ€§
        duration_diff = abs(pause1.duration - pause2.duration)
        max_duration = max(pause1.duration, pause2.duration)
        duration_similarity = 1 - (duration_diff / max_duration) if max_duration > 0 else 1
        
        # ç»¼åˆè¯„åˆ†
        final_score = (
            0.5 * overlap_ratio +      # é‡å æ˜¯æœ€é‡è¦çš„
            0.3 * distance_score +     # ä¸­å¿ƒè·ç¦»
            0.2 * duration_similarity  # æ—¶é•¿ç›¸ä¼¼æ€§
        )
        
        return final_score
    
    def _create_dual_validated_pause(self, mixed_pause: VocalPause, separated_pause: VocalPause, 
                                   separation_result: SeparationResult, match_score: float) -> ValidatedPause:
        """åˆ›å»ºåŒè·¯éªŒè¯çš„åœé¡¿"""
        # ä½¿ç”¨åŠ æƒå¹³å‡èåˆä¸¤ä¸ªæ£€æµ‹ç»“æœ
        fused_start = (mixed_pause.start_time * self.mixed_weight + 
                      separated_pause.start_time * self.separated_weight)
        fused_end = (mixed_pause.end_time * self.mixed_weight + 
                    separated_pause.end_time * self.separated_weight)
        fused_duration = fused_end - fused_start
        
        # ç½®ä¿¡åº¦æå‡ï¼ˆåŒè·¯éªŒè¯åŠ æˆï¼‰
        base_confidence = max(mixed_pause.confidence, separated_pause.confidence)
        boosted_confidence = min(1.0, base_confidence * self.confidence_boost * match_score)
        
        # é€‰æ‹©æ›´ä¼˜çš„åˆ‡å‰²ç‚¹
        if separated_pause.confidence > mixed_pause.confidence:
            cut_point = separated_pause.cut_point
        else:
            cut_point = mixed_pause.cut_point
        
        return ValidatedPause(
            start_time=fused_start,
            end_time=fused_end,
            duration=fused_duration,
            position_type=mixed_pause.position_type,  # ä¿æŒä½ç½®ç±»å‹
            confidence=boosted_confidence,
            cut_point=cut_point,
            mixed_detection=True,
            separated_detection=True,
            separation_confidence=separation_result.separation_confidence,
            validation_method="dual_path_validated",
            mixed_pause=mixed_pause,
            separated_pause=separated_pause
        )
    
    def _create_mixed_only_validated_pause(self, mixed_pause: VocalPause, 
                                         separation_result: SeparationResult, 
                                         penalty: bool = False) -> ValidatedPause:
        """åˆ›å»ºä»…æ··éŸ³æ£€æµ‹çš„éªŒè¯åœé¡¿"""
        confidence = mixed_pause.confidence
        
        if penalty:
            confidence *= 0.8  # åº”ç”¨ç½®ä¿¡åº¦æƒ©ç½š
            
        return ValidatedPause(
            start_time=mixed_pause.start_time,
            end_time=mixed_pause.end_time,
            duration=mixed_pause.duration,
            position_type=mixed_pause.position_type,
            confidence=confidence,
            cut_point=mixed_pause.cut_point,
            mixed_detection=True,
            separated_detection=False,
            separation_confidence=separation_result.separation_confidence,
            validation_method="mixed_only" + ("_penalty" if penalty else ""),
            mixed_pause=mixed_pause
        )
    
    def _create_separated_only_validated_pause(self, separated_pause: VocalPause, 
                                             separation_result: SeparationResult) -> ValidatedPause:
        """åˆ›å»ºä»…åˆ†ç¦»æ£€æµ‹çš„éªŒè¯åœé¡¿"""
        # åˆ†ç¦»ç‹¬æœ‰çš„åœé¡¿ï¼Œç½®ä¿¡åº¦åŸºäºåˆ†ç¦»è´¨é‡è°ƒæ•´
        adjusted_confidence = separated_pause.confidence * separation_result.separation_confidence
        
        return ValidatedPause(
            start_time=separated_pause.start_time,
            end_time=separated_pause.end_time,
            duration=separated_pause.duration,
            position_type=separated_pause.position_type,
            confidence=adjusted_confidence,
            cut_point=separated_pause.cut_point,
            mixed_detection=False,
            separated_detection=True,
            separation_confidence=separation_result.separation_confidence,
            validation_method="separated_only",
            separated_pause=separated_pause
        )
    
    def _convert_to_validated_pauses(self, pauses: List[VocalPause], single_path: bool = True, source: str = "mixed") -> List[ValidatedPause]:
        """å°†å•è·¯æ£€æµ‹ç»“æœè½¬æ¢ä¸ºéªŒè¯åœé¡¿æ ¼å¼"""
        validated = []
        
        for pause in pauses:
            validated_pause = ValidatedPause(
                start_time=pause.start_time,
                end_time=pause.end_time,
                duration=pause.duration,
                position_type=pause.position_type,
                confidence=pause.confidence,
                cut_point=pause.cut_point,
                mixed_detection=(source == "mixed"),
                separated_detection=(source == "separated"),
                separation_confidence=0.0,
                validation_method=f"single_path_{source}" if single_path else "fallback",
                mixed_pause=pause if source == "mixed" else None,
                separated_pause=pause if source == "separated" else None
            )
            validated.append(validated_pause)
        
        return validated
    
    def _generate_quality_report(self, validated_pauses: List[ValidatedPause], 
                               processing_stats: Dict) -> Dict:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        if not validated_pauses:
            return {'overall_quality': 0.0, 'confidence_stats': {}, 'validation_stats': {}}
        
        # ç½®ä¿¡åº¦ç»Ÿè®¡
        confidences = [p.confidence for p in validated_pauses]
        confidence_stats = {
            'mean': np.mean(confidences),
            'std': np.std(confidences),
            'min': np.min(confidences),
            'max': np.max(confidences),
            'high_confidence_ratio': sum(1 for c in confidences if c > 0.8) / len(confidences)
        }
        
        # éªŒè¯æ–¹æ³•ç»Ÿè®¡
        validation_methods = {}
        for pause in validated_pauses:
            method = pause.validation_method
            validation_methods[method] = validation_methods.get(method, 0) + 1
        
        validation_stats = {
            'methods_count': validation_methods,
            'dual_validated_ratio': validation_methods.get('dual_path_validated', 0) / len(validated_pauses),
            'mixed_only_ratio': (validation_methods.get('mixed_only', 0) + validation_methods.get('mixed_only_penalty', 0)) / len(validated_pauses),
            'separated_only_ratio': validation_methods.get('separated_only', 0) / len(validated_pauses)
        }
        
        # æ€»ä½“è´¨é‡è¯„åˆ†
        overall_quality = (
            0.4 * confidence_stats['mean'] +
            0.3 * validation_stats['dual_validated_ratio'] +
            0.2 * confidence_stats['high_confidence_ratio'] +
            0.1 * min(1.0, processing_stats.get('separation_confidence', 0))
        )
        
        return {
            'overall_quality': overall_quality,
            'confidence_stats': confidence_stats,
            'validation_stats': validation_stats,
            'processing_stats': processing_stats
        }
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        if not self.stats['processing_times']:
            return self.stats
        
        processing_times = self.stats['processing_times']
        enhanced_stats = dict(self.stats)
        enhanced_stats.update({
            'avg_processing_time': np.mean(processing_times),
            'dual_path_usage_rate': self.stats['dual_path_used'] / max(1, self.stats['total_detections']),
            'high_quality_rate': self.stats['high_quality_separations'] / max(1, self.stats['dual_path_used']),
            'backend_info': self.separator.get_backend_info()
        })
        
        return enhanced_stats
    
    def __str__(self) -> str:
        return f"DualPathVocalDetector(dual_enabled={self.enable_dual_detection}, detections={self.stats['total_detections']})"