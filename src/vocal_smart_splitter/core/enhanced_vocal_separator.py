#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# File: src/vocal_smart_splitter/core/enhanced_vocal_separator.py
# AI-SUMMARY: æ£€æµ‹ä¸“ç”¨é«˜ç²¾åº¦äººå£°åˆ†ç¦»å™¨ï¼Œæ”¯æŒMDX23/Demucs v4ç­‰å…ˆè¿›åˆ†ç¦»åç«¯ï¼Œä¸“é—¨ç”¨äºæå‡åœé¡¿æ£€æµ‹ç²¾åº¦

import os
import sys
import time  # ç»Ÿä¸€åœ¨é¡¶éƒ¨å¯¼å…¥timeæ¨¡å—
import numpy as np
import librosa
import logging
import tempfile
import subprocess
import glob
from typing import Tuple, Dict, Optional, Union, List
from pathlib import Path
from dataclasses import dataclass

from ..utils.config_manager import get_config
from .vocal_separator import VocalSeparator  # ç»§æ‰¿ç°æœ‰åˆ†ç¦»å™¨
from pathlib import Path  # æ·»åŠ Pathå¯¼å…¥

logger = logging.getLogger(__name__)

@dataclass
class SeparationResult:
    """äººå£°åˆ†ç¦»ç»“æœæ•°æ®ç»“æ„"""
    vocal_track: np.ndarray      # åˆ†ç¦»çš„äººå£°è½¨é“
    instrumental_track: Optional[np.ndarray] = None  # å™¨ä¹è½¨é“ï¼ˆå¯é€‰ï¼‰
    separation_confidence: float = 0.0  # åˆ†ç¦»è´¨é‡ç½®ä¿¡åº¦ (0-1)
    backend_used: str = "unknown"       # ä½¿ç”¨çš„åˆ†ç¦»åç«¯
    processing_time: float = 0.0        # å¤„ç†è€—æ—¶ï¼ˆç§’ï¼‰
    quality_metrics: Dict = None        # è´¨é‡æŒ‡æ ‡

class EnhancedVocalSeparator:
    """æ£€æµ‹ä¸“ç”¨é«˜ç²¾åº¦äººå£°åˆ†ç¦»å™¨
    
    è®¾è®¡ç†å¿µï¼š
    1. é«˜è´¨é‡åç«¯æ”¯æŒï¼šMDX23(ä¸»æ¨) / Demucs v4(å¤‡é€‰)
    2. æ£€æµ‹ä¸“ç”¨ï¼šåªè¿”å›å†…å­˜æ•°æ®ï¼Œä¸ä¿å­˜æ–‡ä»¶ï¼Œä¼˜åŒ–æ€§èƒ½
    3. è´¨é‡è¯„ä¼°ï¼šè‡ªåŠ¨è¯„ä¼°åˆ†ç¦»è´¨é‡ï¼Œä¸ºåŒè·¯æ£€æµ‹æä¾›ç½®ä¿¡åº¦
    4. æ™ºèƒ½é™çº§ï¼šä¼˜å…ˆä½¿ç”¨MDX23ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°Demucs
    """
    
    def __init__(self, sample_rate: int = 44100):
        """åˆå§‹åŒ–å¢å¼ºå‹åˆ†ç¦»å™¨
        
        Args:
            sample_rate: éŸ³é¢‘é‡‡æ ·ç‡
        """
        self.sample_rate = sample_rate
        
        # ä»é…ç½®åŠ è½½å‚æ•°ï¼Œä½†ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡å¼ºåˆ¶è®¾ç½®
        import os
        forced_backend = os.environ.get('FORCE_SEPARATION_BACKEND')
        if forced_backend:
            self.backend = forced_backend
            self.enable_fallback = False  # å¼ºåˆ¶æ¨¡å¼ä¸å…è®¸é™çº§
            logger.info(f"âœ“ æ£€æµ‹åˆ°å¼ºåˆ¶åç«¯è®¾ç½®: {forced_backend}")
        else:
            self.backend = get_config('enhanced_separation.backend', 'mdx23')
            self.enable_fallback = get_config('enhanced_separation.enable_fallback', True)
            
        self.min_confidence_threshold = get_config('enhanced_separation.min_separation_confidence', 0.7)
        
        # åˆå§‹åŒ–åç«¯çŠ¶æ€
        self.backend_status = {
            'mdx23': {'available': False, 'error': None},
            'demucs_v4': {'available': False, 'error': None}
        }
        
        # æ£€æŸ¥å’Œåˆå§‹åŒ–é«˜ç²¾åº¦åç«¯
        self._initialize_backends()
        
        logger.info(f"å¢å¼ºå‹åˆ†ç¦»å™¨åˆå§‹åŒ–å®Œæˆ - ä¸»åç«¯: {self.backend}")
        
    def _initialize_backends(self):
        """åˆå§‹åŒ–å’Œæ£€æµ‹å„åˆ†ç¦»åç«¯çš„å¯ç”¨æ€§"""
        
        # æ£€æµ‹MDX23åç«¯
        if self.backend == 'mdx23' or self.enable_fallback:
            self._check_mdx23_availability()
            
        # æ£€æµ‹Demucs v4åç«¯  
        if self.backend == 'demucs_v4' or self.enable_fallback:
            self._check_demucs_availability()
            
        # æŠ¥å‘Šåç«¯çŠ¶æ€
        available_backends = [name for name, status in self.backend_status.items() if status['available']]
        logger.info(f"å¯ç”¨åˆ†ç¦»åç«¯: {available_backends}")
        
        if not any(self.backend_status[b]['available'] for b in ['mdx23', 'demucs_v4']):
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„é«˜ç²¾åº¦åˆ†ç¦»åç«¯ï¼Œè¯·æ£€æŸ¥MDX23æˆ–Demucså®‰è£…")
    
    def _check_mdx23_availability(self):
        """æ£€æµ‹MDX23åç«¯å¯ç”¨æ€§"""
        try:
            # ä½¿ç”¨ç»å¯¹è·¯å¾„æ£€æŸ¥MDX23é¡¹ç›®
            project_root = Path(__file__).resolve().parents[3]  # å›åˆ°é¡¹ç›®æ ¹ç›®å½• (ä¿®æ­£è·¯å¾„å±‚çº§)
            mdx23_path = project_root / "MVSEP-MDX23-music-separation-model"
            
            logger.info(f"æ£€æŸ¥MDX23è·¯å¾„: {mdx23_path}")
            
            if mdx23_path.exists():
                # æ£€æŸ¥inference.py
                inference_file = mdx23_path / "inference.py"
                if inference_file.exists():
                    logger.info(f"âœ“ æ‰¾åˆ°MDX23 inference.py: {inference_file}")
                    
                    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
                    models_dir = mdx23_path / "models"
                    if models_dir.exists():
                        onnx_files = list(models_dir.glob("*.onnx"))
                        if onnx_files:
                            self.backend_status['mdx23']['available'] = True
                            self.mdx23_project_path = str(mdx23_path)
                            self.mdx23_models_found = [f.name for f in onnx_files]
                            logger.info(f"âœ“ MDX23åç«¯å¯ç”¨ - æ‰¾åˆ°{len(onnx_files)}ä¸ªæ¨¡å‹: {self.mdx23_models_found[:3]}")
                        else:
                            self.backend_status['mdx23']['error'] = "ONNXæ¨¡å‹æ–‡ä»¶ç¼ºå¤±"
                            logger.warning(f"MDX23æ¨¡å‹æ–‡ä»¶ç¼ºå¤±ï¼Œè¯·åœ¨{models_dir}æ”¾ç½®.onnxæ–‡ä»¶")
                    else:
                        self.backend_status['mdx23']['error'] = "modelsç›®å½•ä¸å­˜åœ¨"
                        logger.warning(f"MDX23 modelsç›®å½•ä¸å­˜åœ¨: {models_dir}")
                else:
                    self.backend_status['mdx23']['error'] = "inference.pyä¸å­˜åœ¨"
                    logger.warning(f"MDX23 inference.pyä¸å­˜åœ¨: {inference_file}")
            else:
                self.backend_status['mdx23']['error'] = "MDX23é¡¹ç›®æœªå®‰è£…"
                logger.warning(f"MDX23é¡¹ç›®æœªæ‰¾åˆ°: {mdx23_path}")
                logger.info("å»ºè®®æ‰§è¡Œ: git clone https://github.com/ZFTurbo/MVSEP-MDX23-music-separation-model")
                
        except Exception as e:
            self.backend_status['mdx23']['error'] = str(e)
            logger.error(f"âš ï¸ MDX23åç«¯æ£€æµ‹å¼‚å¸¸: {e}", exc_info=True)
    
    def _try_import_mdx23(self) -> Dict:
        """å°è¯•å¯¼å…¥MDX23ç›¸å…³æ¨¡å—"""
        try:
            # æ–¹æ¡ˆ1ï¼šå°è¯•å¯¼å…¥å·²å®‰è£…çš„MDX23 PythonåŒ…
            try:
                import inference
                return {'success': True, 'method': 'python_module'}
            except ImportError:
                pass
            
            # æ–¹æ¡ˆ2ï¼šæ£€æŸ¥MDX23å¯æ‰§è¡Œæ–‡ä»¶
            mdx23_executable = get_config('enhanced_separation.mdx23.executable_path', 'python inference.py')
            
            # å°è¯•è¿è¡Œhelpå‘½ä»¤æµ‹è¯•å¯ç”¨æ€§
            test_result = subprocess.run(
                [sys.executable, '-c', 'import inference; print("MDX23 available")'],
                capture_output=True, text=True, timeout=10
            )
            
            if test_result.returncode == 0:
                return {'success': True, 'method': 'cli_available'}
            else:
                # æ£€æŸ¥æ˜¯å¦æœ‰ç‹¬ç«‹çš„MDX23é¡¹ç›®ç›®å½•
                mdx23_project_path = get_config('enhanced_separation.mdx23.project_path', './MVSEP-MDX23-music-separation-model')
                if os.path.exists(os.path.join(mdx23_project_path, 'inference.py')):
                    return {'success': True, 'method': 'project_directory', 'path': mdx23_project_path}
                    
                return {'success': False, 'error': 'MDX23æœªæ‰¾åˆ°ï¼Œè¯·å®‰è£…æˆ–é…ç½®æ­£ç¡®è·¯å¾„'}
                
        except subprocess.TimeoutExpired:
            return {'success': False, 'error': 'MDX23æ£€æµ‹è¶…æ—¶'}
        except Exception as e:
            return {'success': False, 'error': f'MDX23æ£€æµ‹å¼‚å¸¸: {e}'}
    
    def _check_mdx23_models(self) -> bool:
        """æ£€æŸ¥MDX23é¢„è®­ç»ƒæ¨¡å‹"""
        try:
            # æ£€æŸ¥ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹è·¯å¾„
            user_model_path = get_config('enhanced_separation.mdx23.model_path', '')
            if user_model_path and os.path.exists(user_model_path):
                logger.info(f"æ‰¾åˆ°ç”¨æˆ·æŒ‡å®šçš„MDX23æ¨¡å‹: {user_model_path}")
                return True
            
            # æ£€æŸ¥é»˜è®¤æ¨¡å‹ç›®å½•
            default_model_dirs = [
                './models',  # é¡¹ç›®æœ¬åœ°æ¨¡å‹ç›®å½•
                './MVSEP-MDX23-music-separation-model/models',  # MDX23é¡¹ç›®æ¨¡å‹ç›®å½•
                os.path.expanduser('~/.cache/mdx23_models'),  # ç”¨æˆ·ç¼“å­˜ç›®å½•
            ]
            
            # å¸¸è§çš„MDX23æ¨¡å‹æ–‡ä»¶åæ¨¡å¼
            model_patterns = [
                '*.pth', '*.onnx', '*.pt',  # PyTorchæ¨¡å‹
                'MDX23C*.pth', 'Kim_Vocal*.onnx',  # ç‰¹å®šMDX23æ¨¡å‹
            ]
            
            for model_dir in default_model_dirs:
                if not os.path.exists(model_dir):
                    continue
                    
                for pattern in model_patterns:
                    import glob
                    matching_files = glob.glob(os.path.join(model_dir, pattern))
                    if matching_files:
                        logger.info(f"æ‰¾åˆ°MDX23æ¨¡å‹æ–‡ä»¶: {matching_files[0]}")
                        return True
            
            logger.warning("æœªæ‰¾åˆ°MDX23é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶")
            return False
            
        except Exception as e:
            logger.error(f"MDX23æ¨¡å‹æ£€æµ‹å¤±è´¥: {e}")
            return False
    
    def _check_demucs_availability(self):
        """æ£€æµ‹Demucs v4åç«¯å¯ç”¨æ€§"""
        try:
            # å°è¯•å¯¼å…¥demucs
            import demucs.pretrained
            import demucs.apply
            self.backend_status['demucs_v4']['available'] = True
            logger.info("Demucs v4åç«¯å¯ç”¨") 
        except ImportError:
            self.backend_status['demucs_v4']['error'] = "demucsæ¨¡å—æœªå®‰è£…"
            logger.warning("Demucs v4æœªå®‰è£…")
        except Exception as e:
            self.backend_status['demucs_v4']['error'] = str(e)
            logger.warning(f"Demucs v4åç«¯æ£€æµ‹å¤±è´¥: {e}")
    
    def separate_for_detection(self, audio: np.ndarray) -> SeparationResult:
        """ä¸“ç”¨äºæ£€æµ‹çš„äººå£°åˆ†ç¦»ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘æ•°æ®
            
        Returns:
            SeparationResult: åˆ†ç¦»ç»“æœï¼ŒåŒ…å«äººå£°è½¨é“å’Œè´¨é‡è¯„ä¼°
        """
        logger.debug(f"å¼€å§‹äººå£°åˆ†ç¦»æ£€æµ‹ - ç›®æ ‡åç«¯: {self.backend}")
        
        # é€‰æ‹©æœ€ä¼˜å¯ç”¨åç«¯
        selected_backend = self._select_optimal_backend()
        
        # æ‰§è¡Œåˆ†ç¦»
        if selected_backend == 'mdx23':
            result = self._separate_with_mdx23(audio)
        elif selected_backend == 'demucs_v4':
            result = self._separate_with_demucs(audio)
        else:
            raise RuntimeError(f"âŒ ä¸æ”¯æŒçš„åˆ†ç¦»åç«¯: {selected_backend}")
        
        # è´¨é‡è¯„ä¼°
        result.separation_confidence = self._assess_separation_quality(audio, result.vocal_track)
        
        logger.debug(f"åˆ†ç¦»å®Œæˆ - åç«¯: {result.backend_used}, ç½®ä¿¡åº¦: {result.separation_confidence:.3f}")
        return result
    
    def _select_optimal_backend(self) -> str:
        """é€‰æ‹©æœ€ä¼˜å¯ç”¨åˆ†ç¦»åç«¯"""
        import os
        forced_backend = os.environ.get('FORCE_SEPARATION_BACKEND')
        
        logger.info("=== åˆ†ç¦»åç«¯é€‰æ‹©å†³ç­– ===")
        if forced_backend:
            logger.info(f"ğŸš« å¼ºåˆ¶æ¨¡å¼: å¿…é¡»ä½¿ç”¨ {forced_backend}")
        else:
            logger.info(f"é…ç½®åç«¯: {self.backend}")
            
        logger.info(f"åç«¯çŠ¶æ€æ¦‚è§ˆ:")
        for backend, status in self.backend_status.items():
            if status['available']:
                logger.info(f"  âœ“ {backend}: å¯ç”¨")
            else:
                error_msg = status.get('error', 'æœªçŸ¥é”™è¯¯')
                logger.info(f"  âœ— {backend}: ä¸å¯ç”¨ ({error_msg})")
        
        # å¼ºåˆ¶æ¨¡å¼ï¼šå¿…é¡»ä½¿ç”¨æŒ‡å®šåç«¯
        if forced_backend:
            if self.backend_status.get(forced_backend, {}).get('available', False):
                logger.info(f"âœ“ å¼ºåˆ¶ä½¿ç”¨åç«¯: {forced_backend}")
                if forced_backend == 'mdx23':
                    logger.info(f"  MDX23é¡¹ç›®è·¯å¾„: {getattr(self, 'mdx23_project_path', 'Not Set')}")
                    logger.info(f"  æ‰¾åˆ°æ¨¡å‹: {getattr(self, 'mdx23_models_found', 'None')}")
                return forced_backend
            else:
                error_msg = self.backend_status.get(forced_backend, {}).get('error', 'æœªçŸ¥é”™è¯¯')
                raise RuntimeError(f"âŒ å¼ºåˆ¶åç«¯ {forced_backend} ä¸å¯ç”¨: {error_msg}")
        
        # å¦‚æœç”¨æˆ·æŒ‡å®šäº†backendä¸”å¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨
        if self.backend != 'auto' and self.backend_status.get(self.backend, {}).get('available', False):
            logger.info(f"âœ“ é€‰æ‹©ç”¨æˆ·æŒ‡å®šåç«¯: {self.backend}")
            return self.backend
        
        # è‡ªåŠ¨é€‰æ‹©ï¼šMDX23 > Demucs v4
        if self.backend_status['mdx23']['available']:
            logger.info("âœ“ è‡ªåŠ¨é€‰æ‹©MDX23åç«¯ï¼ˆæœ€é«˜è´¨é‡ï¼‰")
            logger.info(f"  MDX23é¡¹ç›®è·¯å¾„: {getattr(self, 'mdx23_project_path', 'Not Set')}")
            logger.info(f"  æ‰¾åˆ°æ¨¡å‹: {getattr(self, 'mdx23_models_found', 'None')}")
            return 'mdx23'
        elif self.backend_status['demucs_v4']['available']:
            logger.info("âœ“ è‡ªåŠ¨é€‰æ‹©Demucs v4åç«¯")
            return 'demucs_v4'
        else:
            # æ²¡æœ‰å¯ç”¨çš„é«˜è´¨é‡åç«¯
            logger.error("âŒ æ‰€æœ‰é«˜è´¨é‡åˆ†ç¦»åç«¯éƒ½ä¸å¯ç”¨")
            logger.error("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            if self.backend_status['mdx23']['error']:
                logger.error(f"  MDX23é”™è¯¯: {self.backend_status['mdx23']['error']}")
            if self.backend_status['demucs_v4']['error']:
                logger.error(f"  Demucsé”™è¯¯: {self.backend_status['demucs_v4']['error']}")
            logger.error("å»ºè®®æ£€æŸ¥:")
            logger.error("  1. MDX23é¡¹ç›®æ˜¯å¦æ­£ç¡®å…‹éš†åˆ°é¡¹ç›®æ ¹ç›®å½•")
            logger.error("  2. æ¨¡å‹æ–‡ä»¶æ˜¯å¦å·²ä¸‹è½½åˆ° models/ ç›®å½•")
            logger.error("  3. Demucsæ˜¯å¦æ­£ç¡®å®‰è£…")
            raise RuntimeError("âŒ æ²¡æœ‰å¯ç”¨çš„äººå£°åˆ†ç¦»åç«¯ï¼Œæ— æ³•è¿›è¡Œçº¯äººå£°æ£€æµ‹")
    
    def _separate_with_mdx23(self, audio: np.ndarray) -> SeparationResult:
        """ä½¿ç”¨MDX23è¿›è¡Œåˆ†ç¦»"""
        start_time = time.time()
        
        try:
            # æ–¹æ¡ˆ1ï¼šå°è¯•ç›´æ¥Pythonæ¥å£ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if hasattr(self, '_mdx23_python_available'):
                return self._separate_with_mdx23_python(audio, start_time)
                
            # æ–¹æ¡ˆ2ï¼šé€šè¿‡CLIæ¥å£åˆ†ç¦»ï¼ˆä¸»è¦æ–¹æ¡ˆï¼‰
            return self._separate_with_mdx23_cli(audio, start_time)
            
        except Exception as e:
            logger.warning(f"MDX23åˆ†ç¦»å¤±è´¥ï¼Œå°è¯•é™çº§åˆ°Demucs v4: {e}")
            # è‡ªåŠ¨é™çº§åˆ°Demucs v4
            if self.backend_status['demucs_v4']['available']:
                return self._separate_with_demucs(audio)
            else:
                raise RuntimeError(f"âŒ MDX23åˆ†ç¦»å¤±è´¥ä¸”æ— Demucså¤‡é€‰: {e}")
    
    def _separate_with_mdx23_cli(self, audio: np.ndarray, start_time: float) -> SeparationResult:
        """é€šè¿‡CLIæ¥å£ä½¿ç”¨MDX23åˆ†ç¦»"""
        temp_dir = None
        try:
            logger.info("=== å¼€å§‹MDX23 CLIåˆ†ç¦» ===")
            # è½»é‡è¯Šæ–­ï¼šç¡®è®¤å³å°†ç”¨äºå­è¿›ç¨‹çš„è§£é‡Šå™¨ä¸è™šæ‹Ÿç¯å¢ƒ
            import sys as _sys, os as _os
            logger.info(f"PYTHON (CLI): {_sys.executable}")
            logger.info(f"VIRTUAL_ENV: {_os.environ.get('VIRTUAL_ENV', '')}")

            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = tempfile.mkdtemp(prefix='mdx23_separation_')
            input_file = os.path.join(temp_dir, 'input.wav')
            output_dir = os.path.join(temp_dir, 'output')
            os.makedirs(output_dir, exist_ok=True)
            
            logger.info(f"ä¸´æ—¶ç›®å½•: {temp_dir}")
            logger.info(f"è¾“å…¥æ–‡ä»¶: {input_file}")
            logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
            
            # ä¿å­˜è¾“å…¥éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            import soundfile as sf
            sf.write(input_file, audio, self.sample_rate)
            logger.info(f"éŸ³é¢‘å†™å…¥å®Œæˆ: {input_file} (é•¿åº¦: {len(audio)}æ ·æœ¬, é‡‡æ ·ç‡: {self.sample_rate}Hz)")
            
            # å‡†å¤‡MDX23å‘½ä»¤å‚æ•°
            mdx23_cmd = self._build_mdx23_command(input_file, output_dir)
            
            # ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œå‘½ä»¤
            project_root = Path(__file__).resolve().parents[3]  # ä½¿ç”¨Pathè€Œä¸æ˜¯os.path (ä¿®æ­£è·¯å¾„å±‚çº§)
            
            logger.info(f"MDX23å‘½ä»¤: {' '.join(mdx23_cmd)}")
            logger.info(f"æ‰§è¡Œç›®å½•: {project_root}")
            logger.info(f"MDX23é¡¹ç›®è·¯å¾„: {self.mdx23_project_path}")
            
            # éªŒè¯MDX23è·¯å¾„å’Œæ–‡ä»¶
            mdx23_inference = Path(self.mdx23_project_path) / "inference.py"
            if not mdx23_inference.exists():
                raise FileNotFoundError(f"MDX23 inference.pyä¸å­˜åœ¨: {mdx23_inference}")
            
            logger.info("å¼€å§‹æ‰§è¡ŒMDX23å‘½ä»¤...")
            result = subprocess.run(
                mdx23_cmd, 
                capture_output=True, 
                text=True,
                timeout=get_config('enhanced_separation.mdx23.timeout', 300),  # 5åˆ†é’Ÿè¶…æ—¶
                cwd=str(project_root)  # åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ
            )
            
            logger.info(f"MDX23å‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç : {result.returncode}")
            if result.stdout:
                logger.info(f"MDX23è¾“å‡º: {result.stdout}")
            if result.stderr:
                logger.warning(f"MDX23é”™è¯¯: {result.stderr}")
            
            if result.returncode != 0:
                logger.error(f"MDX23æ‰§è¡Œå¤±è´¥ (è¿”å›ç  {result.returncode})")
                raise RuntimeError(f"MDX23æ‰§è¡Œå¤±è´¥: {result.stderr}")
            
            # æ£€æŸ¥è¾“å‡ºç›®å½•
            output_files = list(Path(output_dir).glob("*"))
            logger.info(f"è¾“å‡ºç›®å½•å†…å®¹: {[f.name for f in output_files]}")
            
            # è¯»å–åˆ†ç¦»ç»“æœ
            vocal_file = self._find_vocal_output_file(output_dir)
            if not vocal_file:
                logger.error(f"æœªæ‰¾åˆ°MDX23è¾“å‡ºçš„äººå£°æ–‡ä»¶ï¼Œè¾“å‡ºç›®å½•: {output_dir}")
                logger.error(f"è¾“å‡ºæ–‡ä»¶åˆ—è¡¨: {output_files}")
                raise FileNotFoundError("æœªæ‰¾åˆ°MDX23è¾“å‡ºçš„äººå£°æ–‡ä»¶")
                
            logger.info(f"æ‰¾åˆ°äººå£°æ–‡ä»¶: {vocal_file}")
            vocal_track, sr = librosa.load(vocal_file, sr=self.sample_rate)
            logger.info(f"äººå£°è½¨é“åŠ è½½å®Œæˆ: é•¿åº¦={len(vocal_track)}, é‡‡æ ·ç‡={sr}")
            
            processing_time = time.time() - start_time
            
            result = SeparationResult(
                vocal_track=vocal_track,
                backend_used="mdx23",
                processing_time=processing_time
            )
            
            logger.info(f"âœ“ MDX23åˆ†ç¦»æˆåŠŸå®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            return result
            
        except subprocess.TimeoutExpired:
            logger.error("MDX23å¤„ç†è¶…æ—¶")
            raise RuntimeError("MDX23å¤„ç†è¶…æ—¶")
        except Exception as e:
            logger.error(f"âœ— MDX23 CLIåˆ†ç¦»å¤±è´¥: {e}")
            logger.error(f"å¤±è´¥æ—¶çš„çŠ¶æ€ä¿¡æ¯:")
            logger.error(f"  ä¸´æ—¶ç›®å½•: {temp_dir}")
            logger.error(f"  MDX23é¡¹ç›®è·¯å¾„: {getattr(self, 'mdx23_project_path', 'Not Set')}")
            logger.error(f"  å¯ç”¨æ¨¡å‹: {getattr(self, 'mdx23_models_found', 'None')}")
            raise
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_dir and os.path.exists(temp_dir):
                try:
                    import shutil
                    shutil.rmtree(temp_dir)
                except Exception as e:
                    logger.warning(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
    
    def _build_mdx23_command(self, input_file: str, output_dir: str) -> List[str]:
        """æ„å»ºMDX23å‘½ä»¤è¡Œå‚æ•°"""
        # ä½¿ç”¨ç»å¯¹è·¯å¾„
        project_root = Path(__file__).resolve().parents[3]  # ä¿®æ­£è·¯å¾„å±‚çº§
        mdx23_path = project_root / "MVSEP-MDX23-music-separation-model"
        inference_script = mdx23_path / "inference.py"
        
        # åŸºç¡€å‘½ä»¤
        cmd = [sys.executable, str(inference_script)]
        # é¢„æ£€ï¼šåœ¨åŒä¸€è§£é‡Šå™¨å†…å°è¯•å¯¼å…¥ demucsï¼ˆä¸ CLI ä¸€è‡´ï¼‰
        try:
            probe = subprocess.run(
                [sys.executable, '-c', 'import demucs,sys;print("demucs_ok")'],
                capture_output=True, text=True, timeout=10
            )
            if probe.returncode == 0 and 'demucs_ok' in (probe.stdout or ''):
                logger.info("Demucs import preflight: OK")
            else:
                logger.warning(f"Demucs import preflight: FAIL (rc={probe.returncode}) stdout={probe.stdout!r} stderr={probe.stderr!r}")
        except Exception as _e:
            logger.warning(f"Demucs import preflight exception: {_e}")

        # è®°å½•å³å°†æ‰§è¡Œçš„å‘½ä»¤ï¼ˆç²¾ç®€ï¼‰
        try:
            logger.info(f"MDX23 CLI cmd: {' '.join(cmd)}")
        except Exception:
            pass

        # æ·»åŠ è¾“å…¥è¾“å‡ºå‚æ•°
        cmd.extend(['--input_audio', input_file])
        cmd.extend(['--output_folder', output_dir])
        
        # æ¨¡å‹é€‰æ‹©å‚æ•°
        use_kim_model_1 = get_config('enhanced_separation.mdx23.use_kim_model_1', False)
        if use_kim_model_1:
            cmd.append('--use_kim_model_1')
            logger.info("MDX23ä½¿ç”¨æ¨¡å‹: Kim Model 1")
        else:
            logger.info("MDX23ä½¿ç”¨æ¨¡å‹: Kim Model 2 (é»˜è®¤)")
        
        # GPU/CPU æ¨¡å¼
        import torch
        use_cpu = False
        if not torch.cuda.is_available() or not get_config('enhanced_separation.gpu_config.enable_gpu', True):
            cmd.append('--cpu')
            use_cpu = True
            logger.info("MDX23ä½¿ç”¨CPUæ¨¡å¼")
        else:
            # å¤§GPUæ¨¡å¼
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            if gpu_memory > 8 and get_config('enhanced_separation.gpu_config.large_gpu_mode', True):
                cmd.append('--large_gpu')
                logger.info(f"MDX23å¯ç”¨å¤§GPUæ¨¡å¼ (GPUå†…å­˜: {gpu_memory:.1f}GB)")
            else:
                logger.info(f"MDX23ä½¿ç”¨æ ‡å‡†GPUæ¨¡å¼ (GPUå†…å­˜: {gpu_memory:.1f}GB)")
        
        # é‡å å‚æ•° - ä¿®å¤å‚æ•°åç§°
        overlap_large = get_config('enhanced_separation.mdx23.overlap_large', 0.6)
        overlap_small = get_config('enhanced_separation.mdx23.overlap_small', 0.5)
        chunk_size = get_config('enhanced_separation.mdx23.chunk_size', 1000000)  # ä½¿ç”¨é»˜è®¤å€¼
        
        cmd.extend(['--overlap_large', str(overlap_large)])
        cmd.extend(['--overlap_small', str(overlap_small)])
        cmd.extend(['--chunk_size', str(chunk_size)])
        
        # æ·»åŠ å•æ¬¡è¾“å‡ºå‚æ•°ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
        cmd.append('--single_onnx')
        cmd.append('--only_vocals')  # åªè¾“å‡ºäººå£°
        
        logger.info(f"MDX23å‚æ•°: chunk_size={chunk_size}, overlap_large={overlap_large}, overlap_small={overlap_small}")
        
        return cmd
    
    def _find_vocal_output_file(self, output_dir: str) -> Optional[str]:
        """åœ¨è¾“å‡ºç›®å½•ä¸­æŸ¥æ‰¾äººå£°æ–‡ä»¶"""
        # MDX23è¾“å‡ºæ–‡ä»¶çš„å¸¸è§å‘½åæ¨¡å¼
        vocal_patterns = [
            '*_vocals.wav',
            '*_vocal.wav', 
            '*_voice.wav',
            'vocals_*.wav',
            'vocal_*.wav'
        ]
        
        import glob
        for pattern in vocal_patterns:
            matches = glob.glob(os.path.join(output_dir, pattern))
            if matches:
                return matches[0]  # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ–‡ä»¶
        
        # å¦‚æœæ²¡æ‰¾åˆ°ç‰¹å®šæ¨¡å¼ï¼ŒæŸ¥æ‰¾æ‰€æœ‰wavæ–‡ä»¶
        all_wav_files = glob.glob(os.path.join(output_dir, '*.wav'))
        if all_wav_files:
            # è¿”å›æœ€å¤§çš„æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ä¸»è¦è¾“å‡ºï¼‰
            return max(all_wav_files, key=os.path.getsize)
            
        return None
    
    def _separate_with_mdx23_python(self, audio: np.ndarray, start_time: float) -> SeparationResult:
        """é€šè¿‡Pythonæ¥å£ä½¿ç”¨MDX23åˆ†ç¦»ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        try:
            # è¿™éƒ¨åˆ†éœ€è¦MDX23æä¾›Python API
            # ç›®å‰MDX23ä¸»è¦æ˜¯CLIå·¥å…·ï¼ŒPythonæ¥å£å¯èƒ½éœ€è¦è¿›ä¸€æ­¥å¼€å‘
            import inference
            
            # å‡è®¾çš„Python APIè°ƒç”¨ï¼ˆå®é™…éœ€è¦æ ¹æ®MDX23çš„Pythonæ¥å£è°ƒæ•´ï¼‰
            vocal_track = inference.separate_vocals(audio, self.sample_rate)
            
            processing_time = time.time() - start_time
            
            result = SeparationResult(
                vocal_track=vocal_track,
                backend_used="mdx23_python",
                processing_time=processing_time
            )
            
            logger.debug(f"MDX23 Pythonåˆ†ç¦»å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            return result
            
        except Exception as e:
            logger.error(f"MDX23 Pythonæ¥å£åˆ†ç¦»å¤±è´¥: {e}")
            raise
    
    def _separate_with_demucs(self, audio: np.ndarray) -> SeparationResult:
        """ä½¿ç”¨Demucs v4è¿›è¡Œåˆ†ç¦»"""
        start_time = time.time()
        
        try:
            # PyTorch 2.8.0å…¼å®¹æ€§ä¿®å¤ - å¿…é¡»åœ¨å¯¼å…¥demucsä¹‹å‰
            import torch
            import torch.serialization
            
            # åº”ç”¨Demucså…¼å®¹æ€§ä¿®å¤
            try:
                import demucs.htdemucs
                import demucs.hdemucs
                torch.serialization.add_safe_globals([demucs.htdemucs.HTDemucs])
                torch.serialization.add_safe_globals([demucs.hdemucs.HDemucs])
                logger.debug("[COMPAT] Demucså…¼å®¹æ€§ä¿®å¤å·²åº”ç”¨")
            except (ImportError, AttributeError):
                logger.debug("[COMPAT] Demucså…¼å®¹æ€§ä¿®å¤è·³è¿‡")
            
            # ä½¿ç”¨demucsè¿›è¡Œåˆ†ç¦»
            import demucs.pretrained
            import demucs.apply
            
            # ä»é…ç½®è·å–è®¾å¤‡å’Œæ¨¡å‹å‚æ•°
            config_device = get_config('enhanced_separation.demucs_v4.device', 'auto')
            model_name = get_config('enhanced_separation.demucs_v4.model', 'htdemucs')
            segment_size = get_config('enhanced_separation.demucs_v4.segment', 8)
            shifts = get_config('enhanced_separation.demucs_v4.shifts', 1)
            overlap = get_config('enhanced_separation.demucs_v4.overlap', 0.25)
            split = get_config('enhanced_separation.demucs_v4.split', True)
            
            # è®¾å¤‡é€‰æ‹©é€»è¾‘
            if config_device == 'cuda' and torch.cuda.is_available():
                device = 'cuda'
                # GPUå†…å­˜ç®¡ç†ï¼šæ¸…ç†ç¼“å­˜
                torch.cuda.empty_cache()
                gpu_name = torch.cuda.get_device_name()
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                logger.debug(f"ä½¿ç”¨GPU: {gpu_name} ({gpu_memory:.1f}GB)")
            elif config_device == 'auto':
                device = 'cuda' if torch.cuda.is_available() else 'cpu'
                if device == 'cuda':
                    torch.cuda.empty_cache()
                logger.debug(f"è‡ªåŠ¨é€‰æ‹©è®¾å¤‡: {device}")
            else:
                device = 'cpu'
                logger.debug("ä½¿ç”¨CPUæ¨¡å¼")
            
            # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            model = demucs.pretrained.get_model(name=model_name)
            model.to(device)
            
            # å‡†å¤‡éŸ³é¢‘æ•°æ® - ä¿®å¤ç»´åº¦é—®é¢˜
            if audio.ndim == 1:
                # å•å£°é“è½¬ç«‹ä½“å£°
                audio_stereo = np.stack([audio, audio], axis=0)  # [2, length]
            else:
                # ç¡®ä¿æ˜¯ [channels, length] æ ¼å¼
                if audio.shape[0] > audio.shape[1]:
                    audio_stereo = audio.T  # è½¬ç½®ä¸º [channels, length]
                else:
                    audio_stereo = audio
            
            # è½¬æ¢ä¸ºtorchå¼ é‡
            audio_tensor = torch.from_numpy(audio_stereo).float()
            
            # ç¡®ä¿å½¢çŠ¶ä¸º [batch, channels, length]
            if audio_tensor.dim() == 2:
                # [channels, length] -> [1, channels, length]
                audio_tensor = audio_tensor.unsqueeze(0)
            elif audio_tensor.dim() == 1:
                # [length] -> [1, 2, length] (å•å£°é“è½¬ç«‹ä½“å£°)
                audio_tensor = audio_tensor.unsqueeze(0).unsqueeze(0).repeat(1, 2, 1)
            
            # éªŒè¯æœ€ç»ˆå½¢çŠ¶
            if audio_tensor.dim() != 3 or audio_tensor.shape[1] not in [1, 2]:
                logger.error(f"éŸ³é¢‘å¼ é‡å½¢çŠ¶é”™è¯¯: {audio_tensor.shape}ï¼ŒæœŸæœ› [batch, channels, length]")
                raise ValueError(f"éŸ³é¢‘å¼ é‡å½¢çŠ¶é”™è¯¯: {audio_tensor.shape}")
            
            # ç¡®ä¿éŸ³é¢‘åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            audio_tensor = audio_tensor.to(device)
            
            logger.debug(f"Demucsè¾“å…¥å¼ é‡å½¢çŠ¶: {audio_tensor.shape}")
            
            # æ‰§è¡Œåˆ†ç¦»
            try:
                with torch.no_grad():
                    # è‡ªé€‚åº”è°ƒæ•´segmentå¤§å°ä»¥é¿å…å½¢çŠ¶é”™è¯¯
                    audio_length = audio_tensor.shape[-1]
                    # ç¡®ä¿segmentå¤§å°æ˜¯åˆç†çš„ï¼ˆè‡³å°‘ä¸º2ï¼Œæœ€å¤§ä¸ºéŸ³é¢‘é•¿åº¦çš„1/4ï¼‰
                    min_segment = 2
                    max_segment = max(min_segment, audio_length // 8)  # æ›´ä¿å®ˆçš„åˆ†æ®µ
                    adjusted_segment = min(max(min_segment, segment_size), max_segment)
                    
                    logger.debug(f"Demucså‚æ•°: segment={adjusted_segment}, audio_length={audio_length}, input_shape={audio_tensor.shape}")
                    
                    sources = demucs.apply.apply_model(
                        model,
                        audio_tensor,
                        shifts=shifts,
                        split=split,
                        overlap=overlap,
                        segment=adjusted_segment,  # ä½¿ç”¨è°ƒæ•´åçš„åˆ†æ®µå¤§å°
                        progress=False
                    )
            except Exception as demucs_error:
                logger.warning(f"Demucs apply_modelå¤±è´¥: {demucs_error}")
                # å°è¯•ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°
                try:
                    with torch.no_grad():
                        # æœ€ä¿å®ˆçš„å‚æ•°é…ç½®
                        conservative_segment = max(2, audio_tensor.shape[-1] // 16)  # æ›´å°çš„åˆ†æ®µ
                        sources = demucs.apply.apply_model(
                            model,
                            audio_tensor,
                            shifts=1,           # æœ€å°‘çš„shifts
                            split=True,         # å¼ºåˆ¶split
                            overlap=0.05,       # æœ€å°overlap
                            segment=conservative_segment,  # æ›´å°çš„segment
                            progress=False
                        )
                    logger.debug(f"ä½¿ç”¨ä¿å®ˆå‚æ•°æˆåŠŸæ‰§è¡ŒDemucs (segment={conservative_segment})")
                except Exception as conservative_error:
                    logger.error(f"ä¿å®ˆå‚æ•°ä¹Ÿå¤±è´¥: {conservative_error}")
                    # å°è¯•æœ€åçš„æ•‘æ´æªæ–½ï¼šä½¿ç”¨CPUå’Œæœ€å°å‚æ•°
                    try:
                        logger.info("å°è¯•CPUæ¨¡å¼ä½œä¸ºæœ€åæ•‘æ´...")
                        cpu_tensor = audio_tensor.cpu()
                        model_cpu = model.cpu()
                        with torch.no_grad():
                            sources = demucs.apply.apply_model(
                                model_cpu,
                                cpu_tensor,
                                shifts=1,
                                split=True,
                                overlap=0.0,
                                segment=1,
                                progress=False
                            )
                        logger.debug("CPUæ•‘æ´æ¨¡å¼æˆåŠŸ")
                    except Exception:
                        raise demucs_error  # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºåŸå§‹é”™è¯¯
            
            # æå–äººå£°è½¨é“
            logger.debug(f"Demucsè¾“å‡ºå¼ é‡å½¢çŠ¶: {sources.shape}")
            
            # HTDemucsæ¨¡å‹è¾“å‡ºé¡ºåº: drums, bass, other, vocals (ç´¢å¼•3æ˜¯vocals)
            try:
                if sources.dim() == 4:  # [batch, num_sources, channels, time]
                    if sources.shape[1] < 4:
                        raise ValueError(f"è¾“å‡ºæºæ•°é‡ä¸è¶³: {sources.shape[1]} < 4")
                    vocals = sources[0, 3]  # å–ç¬¬ä¸€ä¸ªbatchçš„vocals
                elif sources.dim() == 3:  # [num_sources, channels, time] 
                    if sources.shape[0] < 4:
                        raise ValueError(f"è¾“å‡ºæºæ•°é‡ä¸è¶³: {sources.shape[0]} < 4")
                    vocals = sources[3]  # ç›´æ¥å–vocals
                else:
                    logger.warning(f"æ„å¤–çš„Demucsè¾“å‡ºç»´åº¦: {sources.shape}, å°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªè¾“å‡º")
                    # å°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„è¾“å‡ºä½œä¸ºäººå£°
                    if sources.dim() >= 2:
                        vocals = sources[0] if sources.dim() == 3 else sources[0, 0] if sources.dim() == 4 else sources
                    else:
                        raise ValueError(f"æ— æ³•å¤„ç†çš„Demucsè¾“å‡ºç»´åº¦: {sources.shape}")
                
                logger.debug(f"æå–çš„vocalså½¢çŠ¶: {vocals.shape}")
                
                # è½¬ä¸ºå•å£°é“å¹¶è½¬ä¸ºnumpy
                if vocals.dim() == 2:  # [channels, time]
                    vocal_track = vocals.mean(0).cpu().numpy()  # ç«‹ä½“å£°è½¬å•å£°é“
                elif vocals.dim() == 1:  # [time]
                    vocal_track = vocals.cpu().numpy()  # å·²ç»æ˜¯å•å£°é“
                elif vocals.dim() == 3:  # [batch, channels, time] - é¢å¤–batchç»´åº¦
                    vocal_track = vocals[0].mean(0).cpu().numpy()  # å–ç¬¬ä¸€ä¸ªbatchå¹¶è½¬å•å£°é“
                else:
                    logger.warning(f"æ„å¤–çš„vocalsç»´åº¦: {vocals.shape}, å°è¯•å±•å¹³")
                    # ä½œä¸ºæœ€åæ‰‹æ®µï¼Œå°è¯•å±•å¹³ä¸º1D
                    vocal_track = vocals.flatten().cpu().numpy()
                    
            except Exception as extraction_error:
                logger.error(f"äººå£°æå–å¤±è´¥: {extraction_error}")
                # åº”æ€¥æªæ–½ï¼šä½¿ç”¨æ··éŸ³ä½œä¸ºäººå£°ï¼ˆè™½ç„¶è´¨é‡è¾ƒä½ï¼‰
                logger.warning("ä½¿ç”¨åŸå§‹éŸ³é¢‘ä½œä¸ºåº”æ€¥äººå£°è¾“å‡º")
                vocal_track = audio.mean(axis=0) if audio.ndim > 1 else audio
            
            processing_time = time.time() - start_time
            
            # GPUå†…å­˜æ¸…ç†
            if device == 'cuda':
                del model, sources, audio_tensor, vocals
                torch.cuda.empty_cache()
                logger.debug("GPUå†…å­˜å·²æ¸…ç†")
            
            result = SeparationResult(
                vocal_track=vocal_track,
                instrumental_track=None,
                backend_used="demucs_v4",
                processing_time=processing_time
            )
            
            logger.debug(f"Demucsåˆ†ç¦»å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Demucs v4åˆ†ç¦»å¤±è´¥: {e}")
            raise RuntimeError(f"âŒ Demucs v4åˆ†ç¦»å¤±è´¥ï¼Œæ²¡æœ‰æ›´å¤šå¤‡é€‰æ–¹æ¡ˆ: {e}")
    
    
    def _assess_separation_quality(self, original: np.ndarray, vocals: np.ndarray) -> float:
        """è¯„ä¼°åˆ†ç¦»è´¨é‡ï¼Œè¿”å›ç½®ä¿¡åº¦ (0-1)
        
        Args:
            original: åŸå§‹éŸ³é¢‘
            vocals: åˆ†ç¦»çš„äººå£°
            
        Returns:
            ç½®ä¿¡åº¦åˆ†æ•° (0-1)ï¼Œè¶Šé«˜è¡¨ç¤ºåˆ†ç¦»è´¨é‡è¶Šå¥½
        """
        try:
            # 1. èƒ½é‡æ¯”ä¾‹åˆ†æ
            original_energy = np.mean(original ** 2)
            vocal_energy = np.mean(vocals ** 2)
            
            # é¿å…é™¤é›¶é”™è¯¯
            if original_energy == 0:
                return 0.0
                
            energy_ratio = vocal_energy / original_energy
            
            # 2. é¢‘è°±åˆ†æ - äººå£°é¢‘æ®µèƒ½é‡
            vocal_fft = np.abs(librosa.stft(vocals))
            original_fft = np.abs(librosa.stft(original))
            
            # äººå£°ä¸»è¦é¢‘æ®µ (200-4000 Hz)
            freqs = librosa.fft_frequencies(sr=self.sample_rate)
            vocal_band_mask = (freqs >= 200) & (freqs <= 4000)
            
            vocal_band_energy = np.mean(vocal_fft[vocal_band_mask])
            original_band_energy = np.mean(original_fft[vocal_band_mask])
            
            if original_band_energy == 0:
                return 0.0
                
            spectral_ratio = vocal_band_energy / original_band_energy
            
            # 3. ç»¼åˆè¯„åˆ†
            # å¥½çš„äººå£°åˆ†ç¦»åº”è¯¥ä¿æŒåˆç†çš„èƒ½é‡æ¯”ä¾‹ï¼Œå¹¶ä¸”äººå£°é¢‘æ®µçªå‡º
            energy_score = min(1.0, max(0.0, energy_ratio))  # 0-1èŒƒå›´
            spectral_score = min(1.0, max(0.0, spectral_ratio))  # 0-1èŒƒå›´
            
            # åŠ æƒç»„åˆ
            confidence = 0.4 * energy_score + 0.6 * spectral_score
            
            # åº”ç”¨è´¨é‡é˜ˆå€¼
            if confidence < self.min_confidence_threshold:
                logger.debug(f"åˆ†ç¦»è´¨é‡ä½äºé˜ˆå€¼ ({confidence:.3f} < {self.min_confidence_threshold})")
            
            return confidence
            
        except Exception as e:
            logger.warning(f"è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return 0.5  # è¿”å›ä¸­ç­‰ç½®ä¿¡åº¦
    
    def get_backend_info(self) -> Dict:
        """è·å–åç«¯çŠ¶æ€ä¿¡æ¯"""
        return {
            'current_backend': self.backend,
            'backend_status': self.backend_status,
            'sample_rate': self.sample_rate,
            'min_confidence_threshold': self.min_confidence_threshold
        }
    
    def is_high_quality_backend_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰é«˜è´¨é‡åç«¯å¯ç”¨"""
        return (self.backend_status['mdx23']['available'] or 
                self.backend_status['demucs_v4']['available'])
    
    def __str__(self) -> str:
        available = sum(1 for status in self.backend_status.values() if status['available'])
        return f"EnhancedVocalSeparator(backend={self.backend}, available_backends={available}/3)"
