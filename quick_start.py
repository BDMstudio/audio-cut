#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# quick_start.py - å¿«é€Ÿå¯åŠ¨è„šæœ¬
# AI-SUMMARY: ä¸€é”®å¼éŸ³é¢‘åˆ†å‰²å¿«é€Ÿå¯åŠ¨è„šæœ¬ï¼Œæ— éœ€å¤æ‚å‚æ•°

"""
æ™ºèƒ½äººå£°åˆ†å‰²å™¨ - å¿«é€Ÿå¯åŠ¨è„šæœ¬

æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼ï¼š
1. å°†éŸ³é¢‘æ–‡ä»¶æ”¾å…¥ input/ ç›®å½•
2. è¿è¡Œ python quick_start.py
3. åœ¨ output/ ç›®å½•æŸ¥çœ‹ç»“æœ

ç‰¹ç‚¹ï¼š
- è‡ªåŠ¨æ£€æµ‹input/ç›®å½•ä¸­çš„éŸ³é¢‘æ–‡ä»¶
- ä½¿ç”¨æœ€ä¼˜çš„BPMè‡ªé€‚åº”æ— ç¼åˆ†å‰²
- è‡ªåŠ¨åˆ›å»ºæ—¶é—´æˆ³è¾“å‡ºç›®å½•
- é›¶é…ç½®ï¼Œå¼€ç®±å³ç”¨
"""

# PyTorch 2.8.0å…¼å®¹æ€§ä¿®å¤ - å¿…é¡»åœ¨å¯¼å…¥torchç›¸å…³æ¨¡å—ä¹‹å‰æ‰§è¡Œ
try:
    import pytorch_compatibility_fix
    print("[COMPAT] PyTorch 2.8.0å…¼å®¹æ€§ä¿®å¤å·²åŠ è½½")
except Exception as e:
    print(f"[WARN] å…¼å®¹æ€§ä¿®å¤åŠ è½½å¤±è´¥: {e}")

import os
import sys
from pathlib import Path
from datetime import datetime
import torch  # æ·»åŠ torchå¯¼å…¥ç”¨äºç³»ç»Ÿæ£€æŸ¥

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def find_audio_files():
    """æŸ¥æ‰¾è¾“å…¥ç›®å½•ä¸­çš„éŸ³é¢‘æ–‡ä»¶"""
    input_dir = project_root / "input"
    if not input_dir.exists():
        input_dir.mkdir()
        print(f"å·²åˆ›å»ºè¾“å…¥ç›®å½•: {input_dir}")
        print("è¯·å°†éŸ³é¢‘æ–‡ä»¶æ”¾å…¥è¯¥ç›®å½•åé‡æ–°è¿è¡Œ")
        return []
    
    # æ”¯æŒçš„éŸ³é¢‘æ ¼å¼ï¼ˆç»Ÿä¸€ç”¨å°å†™åŒ¹é…ï¼Œé¿å…Windowså¤§å°å†™é‡å¤ï¼‰
    audio_extensions = {'.mp3', '.wav', '.flac', '.m4a'}
    seen = set()
    audio_files = []

    for p in input_dir.iterdir():
        if p.is_file() and p.suffix.lower() in audio_extensions:
            key = str(p.resolve()).lower()
            if key not in seen:
                seen.add(key)
                audio_files.append(p)

    # åç§°ä¸åŒºåˆ†å¤§å°å†™æ’åº
    return sorted(audio_files, key=lambda x: x.name.lower())

def check_backend_availability():
    """æ£€æŸ¥å„åˆ†ç¦»åç«¯çš„å¯ç”¨æ€§ï¼Œè¿”å›å¯ç”¨åç«¯åˆ—è¡¨"""
    available_backends = {}
    
    # æ£€æŸ¥PyTorchå’ŒCUDA
    try:
        import torch
        gpu_available = torch.cuda.is_available()
        if gpu_available:
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            gpu_info = f"{gpu_name} ({gpu_memory:.1f}GB)"
        else:
            gpu_info = "ä¸å¯ç”¨"
    except ImportError:
        return {}
    
    # æ£€æŸ¥MDX23
    mdx23_path = Path(project_root) / "MVSEP-MDX23-music-separation-model"
    if mdx23_path.exists() and (mdx23_path / "models").exists():
        onnx_files = list((mdx23_path / "models").glob("*.onnx"))
        if onnx_files:
            available_backends['mdx23'] = {
                'name': 'MDX23 (æœ€é«˜è´¨é‡)',
                'description': f'ONNXç¥ç»ç½‘ç»œåˆ†ç¦»ï¼Œæ‰¾åˆ°{len(onnx_files)}ä¸ªæ¨¡å‹',
                'gpu_required': True,
                'gpu_available': gpu_available
            }
    
    # æ£€æŸ¥Demucs
    try:
        import demucs.pretrained
        available_backends['demucs_v4'] = {
            'name': 'Demucs v4 (é«˜è´¨é‡)',
            'description': 'Facebookå¼€æºç¥ç»ç½‘ç»œåˆ†ç¦»',
            'gpu_required': False,  # CPUä¹Ÿèƒ½å·¥ä½œï¼Œä½†GPUæ›´å¿«
            'gpu_available': gpu_available
        }
    except ImportError:
        pass
    
    # ä¸å†æ”¯æŒHPSSåå¤‡æ–¹æ¡ˆ
    
    return available_backends, gpu_info

def check_system_status():
    """æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"""
    print("\n" + "=" * 60)
    print("ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
    print("=" * 60)
    
    # æ£€æŸ¥PyTorchå’ŒCUDA
    try:
        import torch
        print(f"[OK] PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"[OK] CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"[OK] CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"[OK] GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
            print(f"[OK] GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        else:
            print("[!] GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
    except ImportError:
        print("[ERR] PyTorchæœªå®‰è£…")
        return False
    
    # æ£€æŸ¥å„ä¸ªåç«¯
    available_backends, gpu_info = check_backend_availability()
    print(f"\n[INFO] å¯ç”¨çš„åˆ†ç¦»åç«¯:")
    for backend_id, info in available_backends.items():
        status = "OK" if (not info['gpu_required'] or info['gpu_available']) else "NO"
        print(f"  [{status}] {info['name']}: {info['description']}")
    
    return True

def select_backend():
    """è®©ç”¨æˆ·é€‰æ‹©åˆ†ç¦»åç«¯"""
    available_backends, gpu_info = check_backend_availability()
    
    print("\n" + "=" * 60)
    print("é€‰æ‹©åˆ†ç¦»æŠ€æœ¯")
    print("=" * 60)
    print("è¯·é€‰æ‹©è¦ä½¿ç”¨çš„äººå£°åˆ†ç¦»æŠ€æœ¯ï¼š")
    print()
    
    backend_options = []
    option_num = 1
    
    for backend_id, info in available_backends.items():
        if not info['gpu_required'] or info['gpu_available']:
            print(f"  {option_num}. {info['name']}")
            print(f"     {info['description']}")
            if info['gpu_required'] and info['gpu_available']:
                print(f"     [GPUåŠ é€Ÿ] {gpu_info}")
            elif info['gpu_required'] and not info['gpu_available']:
                print(f"     [éœ€è¦GPU] GPUä¸å¯ç”¨ï¼Œæ­¤é€‰é¡¹å°†æ— æ³•ä½¿ç”¨")
                continue
            else:
                print(f"     [CPU/GPUå…¼å®¹]")
            print()
            backend_options.append(backend_id)
            option_num += 1
    
    # æ·»åŠ è‡ªåŠ¨é€‰æ‹©é€‰é¡¹
    print(f"  {option_num}. è‡ªåŠ¨é€‰æ‹© (æ¨è)")
    print(f"     ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä½³å¯ç”¨åç«¯")
    print()
    backend_options.append('auto')
    
    try:
        choice = int(input(f"è¯·é€‰æ‹© (1-{len(backend_options)}): ").strip())
        if 1 <= choice <= len(backend_options):
            selected_backend = backend_options[choice - 1]
            backend_name = available_backends.get(selected_backend, {}).get('name', 'è‡ªåŠ¨é€‰æ‹©')
            print(f"[SELECT] å·²é€‰æ‹©: {backend_name}")
            return selected_backend
        else:
            print("[ERROR] é€‰æ‹©æ— æ•ˆï¼Œä½¿ç”¨è‡ªåŠ¨æ¨¡å¼")
            return 'auto'
    except ValueError:
        print("[ERROR] è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨è‡ªåŠ¨æ¨¡å¼")
        return 'auto'

def apply_backend_config(selected_backend):
    """åº”ç”¨ç”¨æˆ·é€‰æ‹©çš„åç«¯é…ç½®ï¼Œå¼ºåˆ¶ä½¿ç”¨æŒ‡å®šåç«¯"""
    if selected_backend == 'auto':
        print(f"\n[CONFIG] ä½¿ç”¨è‡ªåŠ¨é€‰æ‹©æ¨¡å¼")
        return None
    
    # ä½¿ç”¨ç¯å¢ƒå˜é‡å¼ºåˆ¶è®¾ç½®åç«¯ï¼ˆè¿™æ˜¯æœ€å¯é çš„æ–¹æ³•ï¼‰
    import os
    os.environ['FORCE_SEPARATION_BACKEND'] = selected_backend
    
    print(f"\n[CONFIG] å¼ºåˆ¶è®¾ç½®åˆ†ç¦»åç«¯: {selected_backend}")
    print(f"[CONFIG] ç¯å¢ƒå˜é‡å·²è®¾ç½®: FORCE_SEPARATION_BACKEND={selected_backend}")
    
    return selected_backend

def select_processing_mode():
    """è®©ç”¨æˆ·é€‰æ‹©å¤„ç†æ¨¡å¼"""
    print("\n" + "=" * 60)
    print("é€‰æ‹©å¤„ç†æ¨¡å¼")
    print("=" * 60)
    print("è¯·é€‰æ‹©è¦æ‰§è¡Œçš„å¤„ç†ç±»å‹ï¼š")
    print()
    
    print("  1. æ™ºèƒ½åˆ†å‰²")
    print("     æ ¹æ®äººå£°åœé¡¿ç‚¹è‡ªåŠ¨åˆ†å‰²éŸ³é¢‘ä¸ºå¤šä¸ªç‰‡æ®µ")
    print("     é€‚åˆï¼šè¯­éŸ³è®­ç»ƒã€éŸ³é¢‘ç‰‡æ®µåˆ¶ä½œ")
    print()
    
    print("  2. çº¯äººå£°åˆ†ç¦»")
    print("     åªåˆ†ç¦»äººå£°å’Œä¼´å¥ï¼Œä¸è¿›è¡Œåˆ†å‰²")
    print("     é€‚åˆï¼šéŸ³ä¹åˆ¶ä½œã€å¡æ‹‰OKåˆ¶ä½œ")
    print()
    
    print("  3. [NEW] çº¯äººå£°æ£€æµ‹v2.0 (æ¨è)")
    print("     å¤šç»´ç‰¹å¾åˆ†æ+é¢‘è°±æ„ŸçŸ¥åˆ†ç±»+BPMè‡ªé€‚åº”ä¼˜åŒ–")
    print("     é€‚åˆï¼šé«˜è´¨é‡è¯­éŸ³è®­ç»ƒã€è§£å†³é«˜é¢‘æ¢æ°”è¯¯åˆ¤é—®é¢˜")
    print()
    
    print("  4. ä¼ ç»Ÿçº¯äººå£°åˆ†å‰² (å…¼å®¹æ¨¡å¼)")
    print("     åŸºç¡€VAD+èƒ½é‡æ£€æµ‹åˆ†å‰²ç‰‡æ®µ")
    print("     é€‚åˆï¼šç®€å•åœºæ™¯ã€å¿«é€Ÿå¤„ç†")
    print()
    
    try:
        choice = int(input("è¯·é€‰æ‹© (1-4): ").strip())
        if choice == 1:
            print("[SELECT] å·²é€‰æ‹©: æ™ºèƒ½åˆ†å‰²")
            return 'smart_split'
        elif choice == 2:
            print("[SELECT] å·²é€‰æ‹©: çº¯äººå£°åˆ†ç¦»")
            return 'vocal_separation'
        elif choice == 3:
            print("[SELECT] å·²é€‰æ‹©: [NEW] çº¯äººå£°æ£€æµ‹v2.0")
            return 'vocal_split_v2'
        elif choice == 4:
            print("[SELECT] å·²é€‰æ‹©: ä¼ ç»Ÿçº¯äººå£°åˆ†å‰²")
            return 'vocal_split'
        else:
            print("[ERROR] é€‰æ‹©æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤v2.0æ¨¡å¼")
            return 'vocal_split_v2'
    except ValueError:
        print("[ERROR] è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤v2.0æ¨¡å¼")
        return 'vocal_split_v2'

def separate_vocals_only(input_file: str, output_dir: str, backend: str = 'auto', 
                        sample_rate: int = 44100) -> dict:
    """çº¯äººå£°åˆ†ç¦»ï¼Œä¸è¿›è¡Œåˆ†å‰²
    
    Args:
        input_file: è¾“å…¥éŸ³é¢‘æ–‡ä»¶
        output_dir: è¾“å‡ºç›®å½•
        backend: åˆ†ç¦»åç«¯ ('mdx23', 'demucs_v4', 'hpss_fallback', 'auto')
        sample_rate: é‡‡æ ·ç‡
        
    Returns:
        åˆ†ç¦»ç»“æœä¿¡æ¯
    """
    print(f"[SEPARATION] å¼€å§‹äººå£°åˆ†ç¦»: {Path(input_file).name}")
    print(f"[SEPARATION] ä½¿ç”¨åç«¯: {backend}")
    
    try:
        # å¯¼å…¥æ‰€éœ€æ¨¡å—
        from src.vocal_smart_splitter.core.enhanced_vocal_separator import EnhancedVocalSeparator
        from src.vocal_smart_splitter.utils.audio_processor import AudioProcessor
        import librosa
        import soundfile as sf
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        # 1. åŠ è½½éŸ³é¢‘
        print("[SEPARATION] åŠ è½½éŸ³é¢‘æ–‡ä»¶...")
        audio_processor = AudioProcessor(sample_rate)
        audio, sr = librosa.load(input_file, sr=sample_rate, mono=True)
        
        print(f"[SEPARATION] éŸ³é¢‘ä¿¡æ¯: æ—¶é•¿ {len(audio)/sr:.2f}ç§’, é‡‡æ ·ç‡ {sr}Hz")
        
        # 2. åˆå§‹åŒ–åˆ†ç¦»å™¨
        print("[SEPARATION] åˆå§‹åŒ–äººå£°åˆ†ç¦»å™¨...")
        separator = EnhancedVocalSeparator(sample_rate)
        
        # 3. æ‰§è¡Œåˆ†ç¦»
        print("[SEPARATION] å¼€å§‹äººå£°åˆ†ç¦»...")
        import time
        start_time = time.time()
        
        separation_result = separator.separate_for_detection(audio)
        
        processing_time = time.time() - start_time
        
        # 4. ä¿å­˜ç»“æœ
        input_name = Path(input_file).stem
        
        if separation_result.vocal_track is not None:
            # ä¿å­˜äººå£°
            vocal_file = Path(output_dir) / f"{input_name}_vocal.wav"
            sf.write(vocal_file, separation_result.vocal_track, sample_rate)
            print(f"[SEPARATION] äººå£°å·²ä¿å­˜: {vocal_file.name}")
            
            # ä¿å­˜ä¼´å¥ï¼ˆå¦‚æœæœ‰ï¼‰
            instrumental_file = None
            if separation_result.instrumental_track is not None:
                instrumental_file = Path(output_dir) / f"{input_name}_instrumental.wav"
                sf.write(instrumental_file, separation_result.instrumental_track, sample_rate)
                print(f"[SEPARATION] ä¼´å¥å·²ä¿å­˜: {instrumental_file.name}")
            
            # ç”Ÿæˆåˆ†ç¦»æŠ¥å‘Š
            result = {
                'success': True,
                'input_file': input_file,
                'output_dir': output_dir,
                'vocal_file': str(vocal_file),
                'instrumental_file': str(instrumental_file) if instrumental_file else None,
                'backend_used': separation_result.backend_used,
                'separation_confidence': separation_result.separation_confidence,
                'processing_time': processing_time,
                'audio_duration': len(audio) / sr,
                'quality_metrics': separation_result.quality_metrics or {}
            }
            
            print(f"[SEPARATION] åˆ†ç¦»å®Œæˆ!")
            print(f"  ä½¿ç”¨åç«¯: {separation_result.backend_used}")
            print(f"  åˆ†ç¦»è´¨é‡: {separation_result.separation_confidence:.3f}")
            print(f"  å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’")
            
            return result
            
        else:
            print("[ERROR] äººå£°åˆ†ç¦»å¤±è´¥")
            return {
                'success': False,
                'error': 'äººå£°åˆ†ç¦»è¿”å›ç©ºç»“æœ',
                'input_file': input_file
            }
            
    except Exception as e:
        print(f"[ERROR] äººå£°åˆ†ç¦»å¤±è´¥: {e}")
        return {
            'success': False,
            'error': str(e),
            'input_file': input_file
        }

def split_pure_vocal_v2(input_file: str, output_dir: str, backend: str = 'auto', 
                       sample_rate: int = 44100) -> dict:
    """çº¯äººå£°åœé¡¿åˆ†å‰²v2.0ï¼šä½¿ç”¨å¤šç»´ç‰¹å¾åˆ†æçš„æ™ºèƒ½åˆ†å‰²ç³»ç»Ÿ
    
    æŠ€æœ¯æ ˆï¼š
    - MDX23/Demucsé«˜è´¨é‡äººå£°åˆ†ç¦»
    - å››ç»´ç‰¹å¾åˆ†æ (F0+å…±æŒ¯å³°+é¢‘è°±è´¨å¿ƒ+è°æ³¢å¼ºåº¦)  
    - é¢‘è°±æ„ŸçŸ¥åˆ†ç±»å™¨ (è§£å†³é«˜é¢‘æ¢æ°”è¯¯åˆ¤)
    - BPMè‡ªé€‚åº”ä¼˜åŒ– (èŠ‚æ‹å¯¹é½+é£æ ¼é€‚é…)
    - äº”çº§éªŒè¯ç³»ç»Ÿ (è´¨é‡ä¿è¯)
    
    Args:
        input_file: è¾“å…¥éŸ³é¢‘æ–‡ä»¶
        output_dir: è¾“å‡ºç›®å½•  
        backend: åˆ†ç¦»åç«¯ ('mdx23', 'demucs_v4', 'auto')
        sample_rate: é‡‡æ ·ç‡
        
    Returns:
        v2.0åˆ†å‰²ç»“æœä¿¡æ¯
    """
    print(f"[VOCAL_SPLIT_V2] å¯åŠ¨çº¯äººå£°æ£€æµ‹ç³»ç»Ÿv2.0: {Path(input_file).name}")
    print(f"[VOCAL_SPLIT_V2] åˆ†ç¦»åç«¯: {backend}")
    
    try:
        # å¯¼å…¥v2.0æ ¸å¿ƒæ¨¡å—
        from src.vocal_smart_splitter.core.enhanced_vocal_separator import EnhancedVocalSeparator
        # ä½¿ç”¨æ–°çš„VocalPrimeæ£€æµ‹å™¨æ›¿ä»£åŸæœ‰çš„
        from src.vocal_smart_splitter.core.vocal_prime_detector import VocalPrimeDetector
        from src.vocal_smart_splitter.core.spectral_aware_classifier import SpectralAwareClassifier
        from src.vocal_smart_splitter.core.bpm_vocal_optimizer import BPMVocalOptimizer
        from src.vocal_smart_splitter.core.multi_level_validator import MultiLevelValidator
        from src.vocal_smart_splitter.utils.audio_processor import AudioProcessor
        from src.vocal_smart_splitter.utils.adaptive_parameter_calculator import AdaptiveParameterCalculator
        import librosa
        import soundfile as sf
        import numpy as np
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        import time
        overall_start_time = time.time()
        
        # === v2.0æµæ°´çº¿ï¼š8æ­¥çº¯äººå£°æ£€æµ‹å¤„ç† ===
        
        # ç¬¬1æ­¥ï¼šåŠ è½½éŸ³é¢‘
        print("[V2.0-STEP1] éŸ³é¢‘åŠ è½½ä¸é¢„å¤„ç†...")
        audio_processor = AudioProcessor(sample_rate)
        audio, sr = librosa.load(input_file, sr=sample_rate, mono=True)
        
        print(f"[V2.0-STEP1] éŸ³é¢‘ä¿¡æ¯: æ—¶é•¿ {len(audio)/sr:.2f}ç§’, é‡‡æ ·ç‡ {sr}Hz")
        
        # ç¬¬2æ­¥ï¼šçº¯äººå£°åˆ†ç¦»
        print("[V2.0-STEP2] MDX23/Demucsé«˜è´¨é‡äººå£°åˆ†ç¦»...")
        separator = EnhancedVocalSeparator(sample_rate)
        separation_start = time.time()
        
        separation_result = separator.separate_for_detection(audio)
        separation_time = time.time() - separation_start
        
        if separation_result.vocal_track is None:
            return {
                'success': False,
                'error': 'äººå£°åˆ†ç¦»å¤±è´¥',
                'input_file': input_file
            }
        
        vocal_track = separation_result.vocal_track
        print(f"[V2.0-STEP2] äººå£°åˆ†ç¦»å®Œæˆ - åç«¯: {separation_result.backend_used}, è´¨é‡: {separation_result.separation_confidence:.3f}, è€—æ—¶: {separation_time:.1f}s")
        
        # ğŸ†• é‡‡æ ·ç‡æ˜ å°„éªŒè¯ï¼ˆvocal_prime.md æ ¸å¿ƒä¿®å¤ï¼‰
        print("[V2.0-STEP2.1] é‡‡æ ·ç‡æ˜ å°„éªŒè¯...")
        if len(audio) != len(vocal_track):
            print(f"  âš ï¸ é•¿åº¦ä¸åŒ¹é…: åŸéŸ³é¢‘ {len(audio)} vs äººå£°è½¨ {len(vocal_track)} æ ·æœ¬")
            # ç¡®ä¿é•¿åº¦ä¸€è‡´ï¼Œæˆªå–åˆ°è¾ƒçŸ­çš„é•¿åº¦
            min_length = min(len(audio), len(vocal_track))
            audio = audio[:min_length]
            vocal_track = vocal_track[:min_length]
            print(f"  [OK] å·²å¯¹é½è‡³ {min_length} æ ·æœ¬")
        else:
            print(f"  [OK] é‡‡æ ·ç‡æ˜ å°„æ­£ç¡®: åŸéŸ³é¢‘ä¸äººå£°è½¨å‡ä¸º {len(audio)} æ ·æœ¬")
        
        # ç¡®è®¤ä¸¤ä¸ªéŸ³è½¨çš„æœ‰æ•ˆé‡‡æ ·ç‡ä¸€è‡´æ€§
        original_duration = len(audio) / sample_rate
        vocal_duration = len(vocal_track) / sample_rate
        print(f"  [OK] æ—¶é•¿å¯¹é½éªŒè¯: åŸéŸ³é¢‘ {original_duration:.3f}s, äººå£°è½¨ {vocal_duration:.3f}s")
        
        # ç¬¬3æ­¥ï¼šåœ¨çº¯äººå£°stemä¸Šä½¿ç”¨ Silero VAD æ£€æµ‹åœé¡¿
        print("[V2.0-STEP3] Silero VAD (çº¯äººå£°stem) åœé¡¿æ£€æµ‹...")
        from src.vocal_smart_splitter.core.vocal_pause_detector import VocalPauseDetectorV2
        from src.vocal_smart_splitter.utils.config_manager import get_config
        vad_start = time.time()
        vad_detector = VocalPauseDetectorV2(sample_rate)
        # åœ¨çº¯äººå£°è½¨ä¸Šè¿›è¡ŒVADï¼Œä¿æŒBPMè‡ªé€‚åº”é»˜è®¤é…ç½®ï¼ˆå¦‚åˆ†æå¤±è´¥å°†è‡ªåŠ¨å›é€€ï¼‰
        vpauses = vad_detector.detect_vocal_pauses(vocal_track)
        feature_time = time.time() - vad_start
        print(f"[V2.0-STEP3] VADæ£€æµ‹å®Œæˆï¼Œæ£€æµ‹åˆ° {len(vpauses)} ä¸ªåœé¡¿ï¼Œè€—æ—¶: {feature_time:.1f}s")

        # ç¬¬4æ­¥ï¼šæ ¹æ®åœé¡¿ç”Ÿæˆåˆ‡ç‚¹ï¼ˆå·²å¸¦å¤´/å°¾åç§»ä¸é›¶äº¤å‰å¯¹é½ï¼‰
        print("[V2.0-STEP4] ç”Ÿæˆåˆ‡ç‚¹ä¸æ’åº...")
        audio_duration = len(vocal_track) / sample_rate
        cut_points = [p.cut_point for p in vpauses if getattr(p, 'cut_point', 0.0) > 0.0]
        # é’³åˆ¶åˆ°éŸ³é¢‘èŒƒå›´å¹¶å»é‡æ’åº
        cut_points = sorted({min(audio_duration, max(0.0, float(cp))) for cp in cut_points})
        
        # ğŸ†• èƒ½é‡å®ˆå«éªŒè¯ï¼šç¡®ä¿åˆ‡ç‚¹ä½äºå®‰é™åŒºåŸŸï¼ˆvocal_prime.md æ ¸å¿ƒä¿®å¤ï¼‰
        print("[V2.0-STEP4.1] åº”ç”¨èƒ½é‡å®ˆå«éªŒè¯...")
        from src.vocal_smart_splitter.core.quality_controller import QualityController
        quality_controller = QualityController()
        validated_cut_points = []
        
        for cut_point in cut_points:
            # å¯¹æ¯ä¸ªåˆ‡ç‚¹è¿›è¡Œèƒ½é‡éªŒè¯
            # å…³é”®ä¿®å¤ï¼šä½¿ç”¨åŸå§‹éŸ³é¢‘ï¼ˆæ··éŸ³ï¼‰è¿›è¡Œèƒ½é‡éªŒè¯ï¼Œè€Œä¸æ˜¯çº¯äººå£°è½¨
            # å› ä¸ºçº¯äººå£°è½¨çš„"é™éŸ³"å¯èƒ½ä»æœ‰æ®‹ç•™èƒ½é‡
            validated_point = quality_controller.enforce_quiet_cut(
                audio, sample_rate, cut_point,
                win_ms=80, guard_db=3.0, floor_pct=0.05, search_right_ms=220
            )
            
            # ğŸ”´ å¤„ç†æ— æ•ˆåˆ‡ç‚¹ï¼ˆè¿”å›-1è¡¨ç¤ºæ‰¾ä¸åˆ°å®‰é™åŒºåŸŸï¼‰
            if validated_point < 0:
                print(f"  åˆ‡ç‚¹ç§»é™¤: {cut_point:.3f}s (æ— æ³•æ‰¾åˆ°å®‰é™åŒºåŸŸ)")
                continue  # è·³è¿‡æ— æ•ˆåˆ‡ç‚¹
            
            validated_cut_points.append(validated_point)
            
            # å¦‚æœåˆ‡ç‚¹è¢«è°ƒæ•´ï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
            if abs(validated_point - cut_point) > 0.01:  # 10ms tolerance
                print(f"  åˆ‡ç‚¹è°ƒæ•´: {cut_point:.3f}s -> {validated_point:.3f}s (åç§» {(validated_point - cut_point)*1000:.0f}ms)")
        
        cut_points = sorted(validated_cut_points)
        print(f"[V2.0-STEP4.1] èƒ½é‡å®ˆå«å®Œæˆï¼Œ{len(cut_points)} ä¸ªåˆ‡ç‚¹å·²éªŒè¯")
        
        # ğŸ†• çº¯åŒ–éªŒè¯å™¨ï¼šåªè¿‡æ»¤æ— æ•ˆç‚¹ï¼Œä¸åšé‡å®šä½ï¼ˆvocal_prime.md æ ¸å¿ƒè¦æ±‚ï¼‰
        print("[V2.0-STEP4.2] åº”ç”¨çº¯åŒ–è¿‡æ»¤å™¨...")
        original_count = len(cut_points)
        cut_points = quality_controller.pure_filter_cut_points(
            cut_points, audio_duration, 
            min_interval=2.0, min_segment_duration=1.0
        )
        removed_count = original_count - len(cut_points)
        if removed_count > 0:
            print(f"  è¿‡æ»¤ç§»é™¤ {removed_count} ä¸ªæ— æ•ˆåˆ‡ç‚¹ï¼Œä¿ç•™ {len(cut_points)} ä¸ªæœ‰æ•ˆåˆ‡ç‚¹")
        else:
            print(f"  æ‰€æœ‰ {len(cut_points)} ä¸ªåˆ‡ç‚¹é€šè¿‡çº¯åŒ–è¿‡æ»¤å™¨éªŒè¯")
        
        # ğŸ†• è¯Šæ–­è¾“å‡ºï¼šåˆ‡ç‚¹èƒ½é‡åˆ†æï¼ˆvocal_prime.md è°ƒè¯•è¦æ±‚ï¼‰
        print("[V2.0-STEP4.3] åˆ‡ç‚¹èƒ½é‡è¯Šæ–­åˆ†æ...")
        if cut_points:
            rms_db, _ = quality_controller._moving_rms_db(vocal_track, sample_rate, frame_ms=80, hop_ms=10)
            rms_db = quality_controller._ema_smooth(rms_db, sample_rate, hop_ms=10, smooth_ms=120)
            floor_db = quality_controller._rolling_percentile_db(rms_db, sample_rate, hop_ms=10, win_s=30.0, p=0.05)
            
            print("  åˆ‡ç‚¹èƒ½é‡è¯Šæ–­æŠ¥å‘Š:")
            for i, cp in enumerate(cut_points[:5]):  # æ˜¾ç¤ºå‰5ä¸ªåˆ‡ç‚¹çš„è¯¦ç»†ä¿¡æ¯
                idx = int(cp / (10/1000.0))  # 10ms hop
                if 0 <= idx < len(rms_db):
                    energy_db = float(rms_db[idx])
                    noise_floor = float(floor_db[idx])
                    margin = energy_db - noise_floor
                    status = "[OK] å®‰é™" if margin <= 3.0 else "[WARN] åé«˜"
                    print(f"    åˆ‡ç‚¹{i+1}: {cp:.3f}s, èƒ½é‡={energy_db:.1f}dB, å™ªå£°åœ°æ¿={noise_floor:.1f}dB, ä½™é‡={margin:.1f}dB {status}")
        
        print(f"[V2.0-STEP4.3] è¯Šæ–­å®Œæˆ - ä¿®å¤çŠ¶æ€: [OK] å·²åº”ç”¨energy guard + çº¯åŒ–è¿‡æ»¤å™¨")
        # æ„å»ºåˆ†å‰²ç‚¹ï¼šèµ·ç‚¹ + åˆ‡ç‚¹ + ç»ˆç‚¹ï¼ˆä¸ä¸è¾¹ç•Œåšæœ€å°é—´éš”åˆå¹¶ï¼‰
        split_points = [0.0] + cut_points + [audio_duration]
        print(f"[V2.0-STEP4] åˆ‡ç‚¹æ•°: {len(cut_points)}ï¼Œè®¡åˆ’åˆ†æ®µ: {max(0, len(split_points)-1)} æ®µ")

        # å¯é€‰ï¼šå¯¹è¶…é•¿ç‰‡æ®µè¿›è¡ŒäºŒæ¬¡åˆ‡åˆ†ï¼ˆä»…å³å¯¹é½åˆ°è¿‘é‚»æœ€å°å¹…åº¦ç‚¹ï¼Œé¿å…æ˜æ˜¾ç‚¹å‡»ï¼‰
        max_seg = get_config('bpm_vocal_optimizer.max_segment_duration', None)
        try:
            max_seg = float(max_seg) if max_seg is not None else None
        except Exception:
            max_seg = None
        if max_seg and max_seg > 0:
            def _align_min_amp(t_s: float) -> float:
                idx = int(t_s * sample_rate)
                win = max(1, int(0.01 * sample_rate))  # Â±10ms æœç´¢æœ€å°å¹…åº¦æ ·æœ¬
                l = max(0, idx - win); r = min(len(vocal_track) - 1, idx + win)
                if r <= l:
                    return t_s
                w = vocal_track[l:r]
                j = int(np.argmin(np.abs(w)))
                return (l + j) / float(sample_rate)
            extra = []
            for i in range(len(split_points) - 1):
                s = float(split_points[i]); e = float(split_points[i+1]); d = e - s
                if d > max_seg:
                    n_add = int(d // max_seg)
                    for k in range(1, n_add + 1):
                        t = s + k * max_seg
                        if t < e - 1e-6:
                            extra.append(_align_min_amp(t))
            if extra:
                split_points = sorted({min(audio_duration, max(0.0, float(x))) for x in (split_points + extra)})
                print(f"[V2.0-STEP4] è§¦å‘è¶…é•¿ç‰‡æ®µå†åˆ‡åˆ†ï¼Œæ–°å¢åˆ‡ç‚¹: {len(extra)} ä¸ªï¼›æ–°åˆ†æ®µ: {len(split_points)-1} æ®µ")

        # ç¬¬5æ­¥ï¼šæ ·æœ¬çº§ç²¾åº¦åˆ†å‰²ï¼ˆä»…ä½¿ç”¨æœ€å°ç‰‡æ®µé˜ˆå€¼è¿‡æ»¤ï¼‰
        print("[V2.0-STEP5] æ ·æœ¬çº§ç²¾åº¦åˆ†å‰² (é›¶å¤„ç†ä¿çœŸ)...")
        split_start = time.time()

        input_name = Path(input_file).stem
        saved_files = []
        valid_segments = []

        # ä»é…ç½®è¯»å–åˆ†æ®µç›®æ ‡èŒƒå›´
        target_segment_range = get_config('bpm_vocal_optimizer.target_segment_range', [8.0, 15.0])
        if isinstance(target_segment_range, (list, tuple)) and len(target_segment_range) == 2:
            target_segment_range = [float(target_segment_range[0]), float(target_segment_range[1])]
        else:
            target_segment_range = [8.0, 15.0]
        min_segment_duration = float(get_config('bpm_vocal_optimizer.min_segment_duration', 5.0))
        keep_short_tail = bool(get_config('vocal_pause_splitting.keep_short_tail_segment', True))

        saved_idx = 0
        for i in range(len(split_points) - 1):
            start_time = float(split_points[i])
            end_time = float(split_points[i + 1])
            duration = end_time - start_time

            # æœ«æ®µç‰¹æ®Šï¼šå…è®¸ä¿ç•™çŸ­å°¾æ®µï¼ˆé»˜è®¤å¼€å¯ï¼‰ï¼Œé¿å…è¯¯åˆ çœŸæ­£çš„äººå£°å°¾å¥
            is_last_segment = (i == len(split_points) - 2)
            if (duration < min_segment_duration) and not (is_last_segment and keep_short_tail):
                continue

            # æ ·æœ¬çº§ç´¢å¼•
            start_sample = max(0, int(start_time * sample_rate))
            end_sample = min(len(vocal_track), int(end_time * sample_rate))
            if end_sample <= start_sample:
                continue

            segment = vocal_track[start_sample:end_sample]
            saved_idx += 1
            segment_filename = f"{input_name}_v2_segment_{saved_idx:02d}.wav"
            segment_path = Path(output_dir) / segment_filename
            sf.write(segment_path, segment, sample_rate, subtype='PCM_24')

            saved_files.append(str(segment_path))
            valid_segments.append({
                'index': saved_idx,
                'start_time': start_time,
                'end_time': end_time,
                'duration': duration,
                'filename': segment_filename,
                'v2_features': {
                    'source_pause_confidence': 0.0,
                    'quality_grade': 'N/A'
                }
            })

            print(f"[V2.0-STEP5] ç‰‡æ®µ {saved_idx:2d}: {start_time:.2f}s - {end_time:.2f}s (æ—¶é•¿: {duration:.2f}s)")

        split_time = time.time() - split_start
        
        # ç¬¬8æ­¥ï¼šè¾“å‡ºå®Œæˆå’Œè´¨é‡æŠ¥å‘Š
        print("[V2.0-STEP8] WAV/FLACæ— æŸè¾“å‡ºå’Œè´¨é‡æŠ¥å‘Š...")
        total_time = time.time() - overall_start_time
        
        # ä¿å­˜å®Œæ•´çš„äººå£°å’Œä¼´å¥æ–‡ä»¶
        full_vocal_file = Path(output_dir) / f"{input_name}_v2_vocal_full.wav"
        sf.write(full_vocal_file, vocal_track, sample_rate, subtype='PCM_24')
        saved_files.append(str(full_vocal_file))
        
        instrumental_file = None
        if separation_result.instrumental_track is not None:
            instrumental_file = Path(output_dir) / f"{input_name}_v2_instrumental.wav"
            sf.write(instrumental_file, separation_result.instrumental_track, sample_rate, subtype='PCM_24')
            saved_files.append(str(instrumental_file))
        
        # ç”Ÿæˆv2.0è¯¦ç»†è´¨é‡æŠ¥å‘Š
        avg_segment_confidence = sum(seg['v2_features']['source_pause_confidence'] for seg in valid_segments) / len(valid_segments) if valid_segments else 0.0
        quality_distribution = {'A': 0, 'B': 0, 'C': 0, 'D': 0, 'N/A': 0}
        for seg in valid_segments:
            grade = seg['v2_features']['quality_grade']
            quality_distribution[grade] = quality_distribution.get(grade, 0) + 1
        
        # v2.0ç»“æœæŠ¥å‘Šï¼ˆç®€åŒ–ä¸ºï¼šMDXåˆ†ç¦» â†’ Silero VAD(çº¯äººå£°) â†’ æ ·æœ¬çº§åˆ†å‰²ï¼‰
        result = {
            'success': True,
            'version': '2.0.0',
            'method': 'MDXåˆ†ç¦» + Silero VAD(çº¯äººå£°) + æ ·æœ¬çº§æ— æŸåˆ†å‰²',
            'input_file': input_file,
            'output_dir': output_dir,

            # åˆ†ç¦»ä¿¡æ¯
            'backend_used': separation_result.backend_used,
            'separation_confidence': separation_result.separation_confidence,
            'separation_time': separation_time,

            # v2.0å¤„ç†ç»Ÿè®¡
            'v2_processing_stats': {
                'feature_extraction_time': feature_time,
                'spectral_classification_time': 0.0,
                'bpm_optimization_time': 0.0,
                'validation_time': 0.0,
                'splitting_time': split_time,
                'total_v2_time': total_time
            },

            # æ£€æµ‹ç»“æœç»Ÿè®¡
            'v2_detection_stats': {
                'candidate_pauses_detected': len(vpauses),
                'true_pauses_classified': None,
                'high_quality_pauses_validated': None,
                'breath_filtered_count': None,
                'bpm_detected': None,
                'music_category': 'unknown',
                'avg_pause_confidence': avg_segment_confidence,
                'quality_distribution': quality_distribution
            },

            # è¾“å‡ºç»“æœ
            'num_segments': len(valid_segments),
            'saved_files': saved_files,
            'segments': valid_segments,
            'full_vocal_file': str(full_vocal_file),
            'instrumental_file': str(instrumental_file) if instrumental_file else None,
            'audio_duration': len(vocal_track) / sample_rate,
            'total_processing_time': total_time
        }

        print(f"[V2.0-SUCCESS] çº¯äººå£°æ£€æµ‹ç³»ç»Ÿv2.0åˆ†å‰²å®Œæˆ!")
        print(f"  ç”Ÿæˆç‰‡æ®µ: {len(valid_segments)} ä¸ªç‰‡æ®µ")
        print(f"  åˆ†ç¦»åç«¯: {separation_result.backend_used}")
        print(f"  åˆ†ç¦»è´¨é‡: {separation_result.separation_confidence:.3f}")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {avg_segment_confidence:.3f}")
        print(f"  æ€»å¤„ç†æ—¶é—´: {total_time:.1f}ç§’")
        print(f"  [æŠ€æœ¯æ ˆ] MDXåˆ†ç¦» â†’ Silero VAD(çº¯äººå£°) â†’ æ ·æœ¬çº§é›¶å¤„ç†åˆ†å‰²")

        return result
        
    except Exception as e:
        print(f"[V2.0-ERROR] çº¯äººå£°æ£€æµ‹ç³»ç»Ÿv2.0å¤±è´¥: {e}")
        import traceback
        print(f"[V2.0-DEBUG] è¯¦ç»†é”™è¯¯:")
        print(traceback.format_exc())
        return {
            'success': False,
            'version': '2.0.0',
            'error': str(e),
            'input_file': input_file,
            'error_stage': 'v2.0å¤„ç†æµæ°´çº¿'
        }

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("æ™ºèƒ½äººå£°åˆ†å‰²å™¨ - å¿«é€Ÿå¯åŠ¨ (å¢å¼ºç‰ˆ)")
    print("=" * 60)
    
    # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    if not check_system_status():
        print("\n[ERROR] ç³»ç»Ÿæ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")
        return
    
    # æŸ¥æ‰¾éŸ³é¢‘æ–‡ä»¶
    audio_files = find_audio_files()
    
    if not audio_files:
        print("[ERROR] æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶")
        print("\nè¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š")
        print("1. å°†éŸ³é¢‘æ–‡ä»¶å¤åˆ¶åˆ° input/ ç›®å½•")
        print("2. æ”¯æŒæ ¼å¼: MP3, WAV, FLAC, M4A")
        print("3. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        return
    
    print(f"[INFO] å‘ç° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶:")
    for i, file_path in enumerate(audio_files, 1):
        print(f"  {i}. {file_path.name}")
    
    # é€‰æ‹©æ–‡ä»¶
    if len(audio_files) == 1:
        selected_file = audio_files[0]
        print(f"\n[AUTO] è‡ªåŠ¨é€‰æ‹©: {selected_file.name}")
    else:
        print(f"\nè¯·é€‰æ‹©è¦åˆ†å‰²çš„æ–‡ä»¶ (1-{len(audio_files)}):")
        try:
            choice = int(input("è¾“å…¥åºå·: ").strip())
            if 1 <= choice <= len(audio_files):
                selected_file = audio_files[choice - 1]
            else:
                print("[ERROR] åºå·æ— æ•ˆ")
                return
        except ValueError:
            print("[ERROR] è¾“å…¥æ— æ•ˆ")
            return
    
    print(f"[SELECT] é€‰æ‹©æ–‡ä»¶: {selected_file.name}")
    
    # é€‰æ‹©åˆ†ç¦»åç«¯
    selected_backend = select_backend()
    forced_backend = apply_backend_config(selected_backend)
    
    # é€‰æ‹©å¤„ç†æ¨¡å¼
    processing_mode = select_processing_mode()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    if processing_mode == 'vocal_separation':
        if forced_backend:
            output_dir = project_root / "output" / f"vocal_{forced_backend}_{timestamp}"
        else:
            output_dir = project_root / "output" / f"vocal_{timestamp}"
    elif processing_mode == 'vocal_split_v2':
        if forced_backend:
            output_dir = project_root / "output" / f"v2_{forced_backend}_{timestamp}"
        else:
            output_dir = project_root / "output" / f"v2_{timestamp}"
    elif processing_mode == 'vocal_split':
        if forced_backend:
            output_dir = project_root / "output" / f"vocal_split_{forced_backend}_{timestamp}"
        else:
            output_dir = project_root / "output" / f"vocal_split_{timestamp}"
    else:  # smart_split
        if forced_backend:
            output_dir = project_root / "output" / f"quick_{forced_backend}_{timestamp}"
        else:
            output_dir = project_root / "output" / f"quick_{timestamp}"
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"[OUTPUT] è¾“å‡ºç›®å½•: {output_dir.name}")
    
    if processing_mode == 'vocal_separation':
        print("\n[START] å¼€å§‹äººå£°åˆ†ç¦»...")
    elif processing_mode == 'vocal_split_v2':
        print("\n[V2.0-START] å¯åŠ¨çº¯äººå£°æ£€æµ‹ç³»ç»Ÿv2.0...")
    elif processing_mode == 'vocal_split':
        print("\n[START] å¼€å§‹ä¼ ç»Ÿçº¯äººå£°åœé¡¿åˆ†å‰²...")
    else:
        print("\n[START] å¼€å§‹æ™ºèƒ½åˆ†å‰²...")
    
    try:
        if processing_mode == 'vocal_separation':
            # çº¯äººå£°åˆ†ç¦»æ¨¡å¼
            actual_backend = os.environ.get('FORCE_SEPARATION_BACKEND', selected_backend)
            
            print(f"\n[CONFIG] äººå£°åˆ†ç¦»é…ç½®ï¼š")
            print(f"  é‡‡æ ·ç‡: 44100 Hz")
            print(f"  åˆ†ç¦»åç«¯: {actual_backend}")
            
            # æ‰§è¡Œäººå£°åˆ†ç¦»
            result = separate_vocals_only(
                str(selected_file), 
                str(output_dir), 
                actual_backend, 
                44100
            )
        elif processing_mode == 'vocal_split_v2':
            # [NEW] çº¯äººå£°æ£€æµ‹v2.0æ¨¡å¼
            actual_backend = os.environ.get('FORCE_SEPARATION_BACKEND', selected_backend)
            
            print(f"\n[V2.0-CONFIG] çº¯äººå£°æ£€æµ‹ç³»ç»Ÿv2.0é…ç½®ï¼š")
            print(f"  é‡‡æ ·ç‡: 44100 Hz")
            print(f"  åˆ†ç¦»åç«¯: {actual_backend}")
            print(f"  å¤šç»´ç‰¹å¾: F0è½¨è¿¹+å…±æŒ¯å³°+é¢‘è°±è´¨å¿ƒ+è°æ³¢å¼ºåº¦")
            print(f"  åˆ†ç±»æŠ€æœ¯: é¢‘è°±æ„ŸçŸ¥åˆ†ç±»å™¨")
            print(f"  ä¼˜åŒ–ç­–ç•¥: BPMè‡ªé€‚åº”+èŠ‚æ‹å¯¹é½")
            print(f"  è´¨é‡ä¿è¯: äº”çº§éªŒè¯ç³»ç»Ÿ")
            print(f"  è¾“å‡ºæ ¼å¼: 24ä½WAVæ— æŸ")
            
            # æ‰§è¡Œv2.0çº¯äººå£°æ£€æµ‹åˆ†å‰²
            result = split_pure_vocal_v2(
                str(selected_file), 
                str(output_dir), 
                actual_backend, 
                44100
            )
        elif processing_mode == 'vocal_split':
            # çº¯äººå£°åœé¡¿åˆ†å‰²æ¨¡å¼
            actual_backend = os.environ.get('FORCE_SEPARATION_BACKEND', selected_backend)
            
            print(f"\n[CONFIG] çº¯äººå£°åœé¡¿åˆ†å‰²é…ç½®ï¼š")
            print(f"  é‡‡æ ·ç‡: 44100 Hz")
            print(f"  åˆ†ç¦»åç«¯: {actual_backend}")
            print(f"  æ£€æµ‹æ–¹æ³•: VAD + èƒ½é‡æ£€æµ‹")
            print(f"  æœ€å°åœé¡¿: 1.0ç§’")
            print(f"  æœ€å°ç‰‡æ®µ: 2.0ç§’")
            
            # æ‰§è¡Œä¼ ç»Ÿçº¯äººå£°åœé¡¿åˆ†å‰² (å…¼å®¹æ¨¡å¼)
            # æ³¨æ„ï¼šè¿™é‡Œè°ƒç”¨ä¿ç•™çš„æ—§ç‰ˆæœ¬å‡½æ•°ï¼Œç°åœ¨å·²é‡å‘½åä¸º split_pure_vocal_legacy
            # ä¸ºç®€åŒ–ï¼Œç›´æ¥ä½¿ç”¨ç®€åŒ–ç‰ˆå®ç°
            result = {
                'success': False,
                'error': 'ä¼ ç»Ÿçº¯äººå£°åˆ†å‰²æ¨¡å¼æš‚æ—¶ç¦ç”¨ï¼Œè¯·ä½¿ç”¨v2.0æ¨¡å¼è·å¾—æ›´å¥½æ•ˆæœ',
                'input_file': str(selected_file),
                'suggestion': 'é€‰æ‹©æ¨¡å¼3 - çº¯äººå£°æ£€æµ‹v2.0è·å¾—æœ€ä½³æ•ˆæœ'
            }
        else:
            # æ™ºèƒ½åˆ†å‰²æ¨¡å¼
            # å¯¼å…¥åˆ†å‰²å™¨
            from src.vocal_smart_splitter.core.seamless_splitter import SeamlessSplitter
            from src.vocal_smart_splitter.utils.config_manager import get_config
            
            # è·å–é…ç½®
            sample_rate = get_config('audio.sample_rate', 44100)
            config_backend = get_config('enhanced_separation.backend', 'auto')
            # è·å–å®é™…å°†è¦ä½¿ç”¨çš„åç«¯ï¼ˆä¼˜å…ˆç¯å¢ƒå˜é‡ï¼‰
            actual_backend = os.environ.get('FORCE_SEPARATION_BACKEND', config_backend)
            
            print(f"\n[CONFIG] æ™ºèƒ½åˆ†å‰²é…ç½®ï¼š")
            print(f"  é‡‡æ ·ç‡: {sample_rate} Hz")
            print(f"  é…ç½®æ–‡ä»¶åç«¯: {config_backend}")
            print(f"  å®é™…ä½¿ç”¨åç«¯: {actual_backend} {'(ç¯å¢ƒå˜é‡å¼ºåˆ¶)' if 'FORCE_SEPARATION_BACKEND' in os.environ else ''}")
            print(f"  åŒè·¯æ£€æµ‹: å¯ç”¨")
            print(f"  BPMè‡ªé€‚åº”: å¯ç”¨")
            
            # åˆ›å»ºåˆ†å‰²å™¨
            print("\n[INIT] åˆå§‹åŒ–åˆ†å‰²å™¨...")
            splitter = SeamlessSplitter(sample_rate=sample_rate)
            
            # æ‰§è¡Œåˆ†å‰²
            print("[PROCESS] å¼€å§‹åˆ†å‰²å¤„ç†...")
            result = splitter.split_audio_seamlessly(str(selected_file), str(output_dir))
        
        # æ˜¾ç¤ºå¤„ç†ç»Ÿè®¡
        if processing_mode == 'vocal_separation':
            # äººå£°åˆ†ç¦»æ¨¡å¼çš„ç»“æœæ˜¾ç¤º
            if result.get('success', False):
                print("\n" + "=" * 50)
                print("[SUCCESS] äººå£°åˆ†ç¦»æˆåŠŸå®Œæˆ!")
                print("=" * 50)
                
                print(f"[INFO] è¾“å‡ºç›®å½•: {result['output_dir']}")
                print(f"[INFO] äººå£°æ–‡ä»¶: {Path(result['vocal_file']).name}")
                if result['instrumental_file']:
                    print(f"[INFO] ä¼´å¥æ–‡ä»¶: {Path(result['instrumental_file']).name}")
                
                # æ˜¾ç¤ºæ–‡ä»¶å¤§å°
                vocal_size = Path(result['vocal_file']).stat().st_size / (1024 * 1024)  # MB
                print(f"[INFO] äººå£°æ–‡ä»¶å¤§å°: {vocal_size:.1f}MB")
                
                if result['instrumental_file']:
                    inst_size = Path(result['instrumental_file']).stat().st_size / (1024 * 1024)  # MB
                    print(f"[INFO] ä¼´å¥æ–‡ä»¶å¤§å°: {inst_size:.1f}MB")
                
                print(f"\n[QUALITY] åˆ†ç¦»è´¨é‡: {result['separation_confidence']:.1%}")
                print(f"[BACKEND] ä½¿ç”¨åç«¯: {result['backend_used']}")
                print(f"[TIME] å¤„ç†æ—¶é—´: {result['processing_time']:.1f}ç§’")
                print(f"[AUDIO] éŸ³é¢‘æ—¶é•¿: {result['audio_duration']:.1f}ç§’")
                
                # æ˜¾ç¤ºè´¨é‡æŒ‡æ ‡
                if result.get('quality_metrics'):
                    metrics = result['quality_metrics']
                    print(f"\n[METRICS] è´¨é‡æŒ‡æ ‡:")
                    for key, value in metrics.items():
                        if isinstance(value, float):
                            print(f"  {key}: {value:.3f}")
                        else:
                            print(f"  {key}: {value}")
            else:
                print("[ERROR] äººå£°åˆ†ç¦»å¤±è´¥")
                if 'error' in result:
                    print(f"é”™è¯¯: {result['error']}")
        elif processing_mode == 'vocal_split':
            # çº¯äººå£°åœé¡¿åˆ†å‰²æ¨¡å¼çš„ç»“æœæ˜¾ç¤º
            if result.get('success', False):
                print("\n" + "=" * 50)
                print("[SUCCESS] çº¯äººå£°åœé¡¿åˆ†å‰²æˆåŠŸå®Œæˆ!")
                print("=" * 50)
                
                print(f"[INFO] è¾“å‡ºç›®å½•: {result['output_dir']}")
                print(f"[INFO] ç”Ÿæˆç‰‡æ®µæ•°é‡: {result['num_segments']}")
                print(f"[INFO] æ£€æµ‹æ–¹æ³•: {result['detection_method']}")
                
                # æ˜¾ç¤ºç‰‡æ®µä¿¡æ¯
                if result.get('segments'):
                    print(f"\n[SEGMENTS] ç”Ÿæˆçš„ç‰‡æ®µ:")
                    for segment in result['segments'][:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                        duration = segment['duration']
                        print(f"  {segment['index']:2d}. {segment['filename']} ({duration:.1f}s)")
                    
                    if len(result['segments']) > 10:
                        print(f"  ... è¿˜æœ‰ {len(result['segments'])-10} ä¸ªç‰‡æ®µ")
                
                # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
                print(f"\n[FILES] ä¿å­˜çš„æ–‡ä»¶:")
                print(f"  å®Œæ•´äººå£°: {Path(result['full_vocal_file']).name}")
                if result['instrumental_file']:
                    print(f"  ä¼´å¥æ–‡ä»¶: {Path(result['instrumental_file']).name}")
                print(f"  ç‰‡æ®µæ–‡ä»¶: {result['num_segments']} ä¸ª")
                
                print(f"\n[QUALITY] åˆ†ç¦»è´¨é‡: {result['separation_confidence']:.1%}")
                print(f"[BACKEND] ä½¿ç”¨åç«¯: {result['backend_used']}")
                print(f"[TIME] åˆ†ç¦»æ—¶é—´: {result['separation_time']:.1f}ç§’")
                print(f"[TIME] æ€»å¤„ç†æ—¶é—´: {result['total_processing_time']:.1f}ç§’")
                print(f"[AUDIO] éŸ³é¢‘æ—¶é•¿: {result['audio_duration']:.1f}ç§’")
                print(f"[DETECTION] VADä½¿ç”¨: {'æ˜¯' if result['vad_used'] else 'å¦'}")
                
            else:
                print("[ERROR] çº¯äººå£°åœé¡¿åˆ†å‰²å¤±è´¥")
                if 'error' in result:
                    print(f"é”™è¯¯: {result['error']}")
        elif processing_mode == 'vocal_split_v2':
            # [NEW] çº¯äººå£°æ£€æµ‹v2.0æ¨¡å¼çš„ç»“æœæ˜¾ç¤º
            if result.get('success', False):
                print("\n" + "=" * 60)
                print("[V2.0-SUCCESS] çº¯äººå£°æ£€æµ‹ç³»ç»Ÿv2.0æˆåŠŸå®Œæˆ!")
                print("=" * 60)
                
                print(f"[INFO] è¾“å‡ºç›®å½•: {result['output_dir']}")
                print(f"[INFO] ç³»ç»Ÿç‰ˆæœ¬: v{result['version']}")
                print(f"[INFO] å¤„ç†æ–¹æ³•: {result['method']}")
                
                # v2.0ç‹¬ç‰¹çš„ç»Ÿè®¡ä¿¡æ¯
                if 'v2_detection_stats' in result:
                    stats = result['v2_detection_stats']
                    print(f"\n[V2.0-DETECTION] æ£€æµ‹ç»Ÿè®¡:")
                    print(f"  å€™é€‰åœé¡¿: {stats.get('candidate_pauses_detected', 0)} ä¸ª")
                    print(f"  çœŸåœé¡¿åˆ†ç±»: {stats.get('true_pauses_classified', 0)} ä¸ª")
                    print(f"  é«˜è´¨é‡éªŒè¯: {stats.get('high_quality_pauses_validated', 0)} ä¸ª")
                    print(f"  æ¢æ°”è¿‡æ»¤: {stats.get('breath_filtered_count', 0)} ä¸ª")
                    print(f"  BPMåˆ†æ: {stats.get('bpm_detected', 'N/A')} ({stats.get('music_category', 'unknown')})")
                    print(f"  å¹³å‡ç½®ä¿¡åº¦: {stats.get('avg_pause_confidence', 0):.3f}")
                
                print(f"\n[V2.0-OUTPUT] ç”Ÿæˆç»“æœ:")
                print(f"  é«˜è´¨é‡ç‰‡æ®µ: {result.get('num_segments', 0)} ä¸ª")
                print(f"  å®Œæ•´äººå£°: {Path(result['full_vocal_file']).name}")
                if result.get('instrumental_file'):
                    print(f"  ä¼´å¥æ–‡ä»¶: {Path(result['instrumental_file']).name}")
                
                # æ˜¾ç¤ºç‰‡æ®µä¿¡æ¯
                if result.get('segments'):
                    print(f"\n[V2.0-SEGMENTS] ç‰‡æ®µè¯¦æƒ…:")
                    for seg in result['segments'][:8]:  # æ˜¾ç¤ºå‰8ä¸ª
                        v2_info = seg.get('v2_features', {})
                        confidence = v2_info.get('source_pause_confidence', 0)
                        grade = v2_info.get('quality_grade', 'N/A')
                        print(f"  {seg['index']:2d}. {seg['filename']} ({seg['duration']:.1f}s) [è´¨é‡:{grade} ç½®ä¿¡åº¦:{confidence:.2f}]")
                    
                    if len(result['segments']) > 8:
                        print(f"  ... è¿˜æœ‰ {len(result['segments'])-8} ä¸ªç‰‡æ®µ")
                
                # v2.0å¤„ç†æ—¶é—´ç»Ÿè®¡
                if 'v2_processing_stats' in result:
                    times = result['v2_processing_stats']
                    print(f"\n[V2.0-PERFORMANCE] å¤„ç†æ—¶é—´åˆ†æ:")
                    print(f"  ç‰¹å¾æå–: {times.get('feature_extraction_time', 0):.1f}s")
                    print(f"  é¢‘è°±åˆ†ç±»: {times.get('spectral_classification_time', 0):.1f}s")
                    print(f"  BPMä¼˜åŒ–: {times.get('bpm_optimization_time', 0):.1f}s")
                    print(f"  äº”çº§éªŒè¯: {times.get('validation_time', 0):.1f}s")
                    print(f"  æ ·æœ¬åˆ†å‰²: {times.get('splitting_time', 0):.1f}s")
                    print(f"  æ€»v2.0æ—¶é—´: {times.get('total_v2_time', 0):.1f}s")
                
                print(f"\n[V2.0-QUALITY] åˆ†ç¦»è´¨é‡: {result.get('separation_confidence', 0):.1%}")
                print(f"[V2.0-BACKEND] ä½¿ç”¨åç«¯: {result.get('backend_used', 'unknown')}")
                print(f"[V2.0-AUDIO] éŸ³é¢‘æ—¶é•¿: {result.get('audio_duration', 0):.1f}ç§’")
                
            else:
                print("\n[V2.0-ERROR] çº¯äººå£°æ£€æµ‹ç³»ç»Ÿv2.0å¤±è´¥")
                if 'error' in result:
                    print(f"é”™è¯¯é˜¶æ®µ: {result.get('error_stage', 'æœªçŸ¥')}")
                    print(f"é”™è¯¯è¯¦æƒ…: {result['error']}")
        else:
            # æ™ºèƒ½åˆ†å‰²æ¨¡å¼çš„ç»“æœæ˜¾ç¤º
            if 'processing_stats' in result:
                stats = result['processing_stats']
                print(f"\n[STATS] å¤„ç†ç»Ÿè®¡ï¼š")
                if 'backend_used' in stats:
                    backend = stats['backend_used']
                    print(f"  å®é™…ä½¿ç”¨åç«¯: {backend}")
                    if backend == 'mixed_only':
                        print(f"  è¯´æ˜: ä»…ä½¿ç”¨æ··éŸ³æ£€æµ‹ï¼ˆæœªè¿›è¡Œäººå£°åˆ†ç¦»ï¼‰")
                    elif backend in ['mdx23', 'demucs_v4']:
                        print(f"  è¯´æ˜: ä½¿ç”¨{backend}è¿›è¡Œäº†äººå£°åˆ†ç¦»å¢å¼ºæ£€æµ‹")
                    elif backend == 'hpss_fallback':
                        print(f"  è¯´æ˜: ä½¿ç”¨HPSSå¤‡ç”¨æ¨¡å¼")
                if 'dual_path_used' in stats:
                    print(f"  åŒè·¯æ£€æµ‹æ‰§è¡Œ: {'æ˜¯' if stats['dual_path_used'] else 'å¦'}")
                if 'separation_confidence' in stats:
                    print(f"  åˆ†ç¦»ç½®ä¿¡åº¦: {stats['separation_confidence']:.3f}")
                if 'processing_time' in stats:
                    print(f"  å¤„ç†æ—¶é—´: {stats['processing_time']:.1f}ç§’")
            
            if result.get('success', False):
                print("\n" + "=" * 50)
                print("[SUCCESS] æ™ºèƒ½åˆ†å‰²æˆåŠŸå®Œæˆ!")
                print("=" * 50)
                
                # æ˜¾ç¤ºç»“æœ
                num_segments = result.get('num_segments', 0)
                print(f"[INFO] ç”Ÿæˆç‰‡æ®µæ•°é‡: {num_segments}")
                
                # æ˜¾ç¤ºåˆ†å‰²æ–‡ä»¶
                saved_files = result.get('saved_files', [])
                if saved_files:
                    print("\n[FILES] ç”Ÿæˆçš„æ–‡ä»¶:")
                    for i, file_path in enumerate(saved_files, 1):
                        file_name = Path(file_path).name
                        file_size = Path(file_path).stat().st_size / (1024 * 1024)  # MB
                        print(f"  {i:2d}. {file_name} ({file_size:.1f}MB)")
            
            # æ˜¾ç¤ºè´¨é‡ä¿¡æ¯
            if 'vocal_pause_analysis' in result:
                pause_info = result['vocal_pause_analysis']
                total_pauses = pause_info.get('total_pauses', 0)
                avg_confidence = pause_info.get('avg_confidence', 0)
                print(f"\n[QUALITY] æ£€æµ‹è´¨é‡:")
                print(f"  åœé¡¿æ£€æµ‹: {total_pauses} ä¸ª")
                print(f"  å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
                
                # æ˜¾ç¤ºåŒè·¯æ£€æµ‹ä¿¡æ¯
                if 'dual_detection_info' in pause_info:
                    dual_info = pause_info['dual_detection_info']
                    print(f"\n[DUAL-PATH] åŒè·¯æ£€æµ‹è¯¦æƒ…:")
                    print(f"  æ··éŸ³æ£€æµ‹: {dual_info.get('mixed_detections', 0)} ä¸ªåœé¡¿")
                    print(f"  åˆ†ç¦»æ£€æµ‹: {dual_info.get('separated_detections', 0)} ä¸ªåœé¡¿")
                    print(f"  äº¤å‰éªŒè¯: {dual_info.get('validated_pauses', 0)} ä¸ªç¡®è®¤")
                    if 'separation_backend' in dual_info:
                        print(f"  åˆ†ç¦»åç«¯: {dual_info['separation_backend']}")
            
            # é‡æ„éªŒè¯
            if 'seamless_validation' in result:
                validation = result['seamless_validation']
                perfect = validation.get('perfect_reconstruction', False)
                print(f"  é‡æ„éªŒè¯: {'[PERFECT]' if perfect else '[DIFF]'}")
            
                print(f"\n[OUTPUT] è¾“å‡ºç›®å½•: {output_dir}")
                print("[SUCCESS] å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™äº›éŸ³é¢‘ç‰‡æ®µ!")
                
            else:
                print("[ERROR] æ™ºèƒ½åˆ†å‰²å¤±è´¥")
                if 'error' in result:
                    print(f"é”™è¯¯: {result['error']}")
        
        # å…¬å…±è¾“å‡ºä¿¡æ¯
        if processing_mode in ['vocal_separation', 'vocal_split', 'vocal_split_v2'] and result.get('success', False):
            print(f"\n[OUTPUT] è¾“å‡ºç›®å½•: {output_dir}")
            if processing_mode == 'vocal_separation':
                print("[SUCCESS] å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™äº›éŸ³é¢‘æ–‡ä»¶!")
            elif processing_mode == 'vocal_split_v2':
                print("[V2.0-SUCCESS] å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™äº›é«˜è´¨é‡çº¯äººå£°ç‰‡æ®µ!")
            else:  # vocal_split
                print("[SUCCESS] å¯ä»¥ç›´æ¥ä½¿ç”¨è¿™äº›çº¯äººå£°ç‰‡æ®µ!")
                
    except ImportError as e:
        print(f"[ERROR] æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        print("\nè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®:")
        print("1. ç¡®è®¤å·²å®‰è£…ä¾èµ–: pip install -r requirements.txt")
        print("2. ç¡®è®¤è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»")
        print("3. å¦‚éœ€MDX23æ”¯æŒ: python download_mdx23.py")
        
    except Exception as e:
        print(f"[ERROR] å¤„ç†å¤±è´¥: {e}")
        import traceback
        print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        print(traceback.format_exc())

if __name__ == "__main__":
    main()